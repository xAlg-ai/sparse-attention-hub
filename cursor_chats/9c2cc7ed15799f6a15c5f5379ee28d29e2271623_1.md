# Plan for implementing adaptive sampling masker
_Exported on 7/19/2025 at 15:52:13 PDT from Cursor (1.2.4)_

---

**User**

I want to implement AdaptiveSamplingMasker <-- which extends from SamplingMasker and SamplingMaskerConfig. I have the following notes.



AdaptiveSamplingConfig:
	base_rate_sampling: Union[int, float], if float it has to be in (0,1)
	epsilon: float (0,1)
	delta: float (0,1)
	init_offset: int
	local_offset: int



Some points:
# Read and understand how other maskers are implemented
# Read and understand how Mask and utlitiy on mask is implemented
# Notes on how to implement add_mask:

# in init

store self.delta_ppf = # cdf^-1 ( 1 - delta)  use norm.ppf(1-self.error_delta) scipy.stats package


pseudo code for add_mask
1. check if previous_mask is full mask, if so return full mask.
2. compute expwts =  exp(raw_attention scores which with max trick) (b,h, q, k)
3. static_denominator = compute denominator by applying previous mask on expwts (b,h, q, 1)
4. create base_sampling_mask : a random_sampling mask of sampling_rate- base sampling rate # create using row_wise 
     sample row wise idx from [init_offset: -local_offset] # probability = base_sampling_rate
5. std_estimate = get sample stdev of expwts (b,h, q, 1) using base_sampling_mask
6. sampled_denominator = compute denominator by applying sampling mask on expwts (b,h, q, 1)
7. estimated_denominator = static_denominator + sampled_denominator

8. compute budget b equating epsilon_allowable_Error and delta_allowable_Error 
	epsilon-allowable-Error = epsilon * estimated_denominator
	delta-allowable-Error = self.delta_ppf  * std_estimate * (n -  / sqrt(b) if b is the budgets

9. construct sampling mask such that each row of the mask we use budgets computed in the previous step. The ids used again are from 	[init_offset: -local_offset]


Understand the sparse_attention_hub folder. Especially how maskers are defined (maskers folder) and also how they are manipulate the Mask ( class and its utility). 

Then create a plan to implement this in adaptive_sampling_v2.md in cursor_chats/plans/ folder which already exists. Do not write any code at this point. Just write the plan. I want to iterate on the plan before moving forward

---

**Cursor**

I'll help you understand the sparse attention hub structure and create a plan for implementing the AdaptiveSamplingMasker. Let me start by exploring the codebase to understand how maskers are implemented and how the Mask class works.


Now let me look at the Mask class to understand how it works:


Now let me look at some existing masker implementations to understand the pattern better:


Now let me check the cursor_chats/plans directory to see if it exists:


Perfect! Now I have a good understanding of the codebase structure. Let me create a comprehensive plan for implementing the AdaptiveSamplingMasker. Based on my analysis, I understand:

1. **Masker Structure**: Maskers extend from `SamplingMasker` and `SamplingMaskerConfig`
2. **Mask Class**: Provides utilities like `create_from_row_wise_idx`, `merge_mask`, `is_full_mask()`
3. **Pattern**: All maskers follow a similar pattern with config validation, registry registration, and `add_mask` method
4. **Key Operations**: Row-wise sampling, mask merging, attention score computation

Now let me create the plan:


```markdown
# AdaptiveSamplingMasker Implementation Plan

## Overview
The AdaptiveSamplingMasker is a sophisticated sampling-based masker that adaptively determines sampling budgets based on statistical error bounds. It combines base sampling with adaptive budget allocation to achieve optimal sparsity while maintaining statistical guarantees.

## Algorithm Summary
The masker uses a two-phase approach:
1. **Base Sampling Phase**: Randomly samples a base fraction of positions
2. **Adaptive Budget Phase**: Computes optimal sampling budgets per row based on statistical error bounds (epsilon, delta)

## Configuration Structure

### AdaptiveSamplingMaskerConfig
```python
@dataclass
class AdaptiveSamplingMaskerConfig(SamplingMaskerConfig):
    base_rate_sampling: Union[int, float]  # Base sampling rate (0,1) if float
    epsilon: float  # Error bound (0,1)
    delta: float   # Confidence bound (0,1)
    init_offset: int  # Start index for sampling
    local_offset: int  # End offset for sampling
```

**Validation Rules:**
- `base_rate_sampling`: If float, must be in (0,1); if int, must be positive
- `epsilon`: Must be in (0,1)
- `delta`: Must be in (0,1)
- `init_offset`: Must be non-negative
- `local_offset`: Must be non-negative

## Core Implementation Plan

### 1. Class Structure
```python
@MaskerRegistry.register(AdaptiveSamplingMaskerConfig)
class AdaptiveSamplingMasker(SamplingMasker):
    def __init__(self, config: AdaptiveSamplingMaskerConfig):
        super().__init__(config)
        # Store configuration parameters
        self.base_rate_sampling = config.base_rate_sampling
        self.epsilon = config.epsilon
        self.delta = config.delta
        self.init_offset = config.init_offset
        self.local_offset = config.local_offset
        
        # Pre-compute delta_ppf for efficiency
        self.delta_ppf = norm.ppf(1 - self.delta)  # scipy.stats.norm
```

### 2. Main add_mask Method Algorithm

#### Step 1: Early Exit Check
```python
if previous_mask.is_full_mask():
    return previous_mask
```

#### Step 2: Extract Dimensions and Compute Attention Scores
```python
batch_size, num_heads, seq_len_queries, seq_len_keys = extract_dimensions(keys, queries)
# Compute raw attention scores with max trick for numerical stability
raw_attention_scores = torch.matmul(queries, keys.transpose(-2, -1))
max_scores = torch.max(raw_attention_scores, dim=-1, keepdim=True)[0]
expwts = torch.exp(raw_attention_scores - max_scores)  # (b, h, q, k)
```

#### Step 3: Compute Static Denominator
```python
# Apply previous mask to expwts to get static contribution
static_denominator = previous_mask.apply_to_tensor(expwts)  # (b, h, q, 1)
```

#### Step 4: Create Base Sampling Mask
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Create base sampling mask using row-wise sampling
num_base_samples = int(self.base_rate_sampling * sampling_range)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 5: Estimate Standard Deviation
```python
# Apply base sampling mask to expwts and compute sample standard deviation
base_sampled_expwts = base_sampling_mask.apply_to_tensor(expwts)  # (b, h, q, num_base_samples)
std_estimate = torch.std(base_sampled_expwts, dim=-1, keepdim=True)  # (b, h, q, 1)
```

#### Step 6: Compute Sampled Denominator
```python
sampled_denominator = base_sampling_mask.apply_to_tensor(expwts)  # (b, h, q, 1)
```

#### Step 7: Estimate Total Denominator
```python
estimated_denominator = static_denominator + sampled_denominator  # (b, h, q, 1)
```

#### Step 8: Compute Adaptive Budgets
```python
# Compute error bounds
epsilon_allowable_error = self.epsilon * estimated_denominator  # (b, h, q, 1)
delta_allowable_error = self.delta_ppf * std_estimate * torch.sqrt(sampling_range)  # (b, h, q, 1)

# Solve for budget b: epsilon_error = delta_ppf * std * sqrt(n) / sqrt(b)
# b = (delta_ppf * std * sqrt(n) / epsilon_error)^2
budget_numerator = self.delta_ppf * std_estimate * torch.sqrt(sampling_range)
budget = torch.clamp(
    (budget_numerator / epsilon_allowable_error) ** 2,
    min=1,  # Minimum 1 sample
    max=sampling_range  # Maximum all available positions
).long()  # (b, h, q, 1)
```

#### Step 9: Create Adaptive Sampling Mask
```python
# For each row, sample according to computed budget
adaptive_row_wise_idx = []
adaptive_data = []

for b in range(batch_size):
    for h in range(num_heads):
        for q in range(seq_len_queries):
            row_budget = budget[b, h, q, 0].item()
            # Sample row_budget indices from [start_idx, end_idx)
            row_indices = torch.randperm(sampling_range, device=keys.device)[:row_budget] + start_idx
            adaptive_row_wise_idx.append(row_indices)
            adaptive_data.append(torch.full_like(row_indices, 1.0, dtype=keys.dtype))

# Convert to tensors and create mask
adaptive_row_wise_idx = torch.stack(adaptive_row_wise_idx).reshape(batch_size, num_heads, seq_len_queries, -1)
adaptive_data = torch.stack(adaptive_data).reshape(batch_size, num_heads, seq_len_queries, -1)

adaptive_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=adaptive_row_wise_idx,
    data=adaptive_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 10: Merge and Return
```python
# Merge base sampling mask with adaptive mask
combined_mask = base_sampling_mask.merge_mask(adaptive_mask, inplace=False)
# Merge with previous mask
return previous_mask.merge_mask(combined_mask, inplace=False)
```

## Key Implementation Considerations

### 1. Numerical Stability
- Use max trick for exponential computation
- Handle edge cases where denominators are zero
- Ensure proper dtype handling throughout

### 2. Efficiency Optimizations
- Pre-compute `delta_ppf` in constructor
- Vectorize budget computation where possible
- Use efficient tensor operations for sampling

### 3. Error Handling
- Validate all configuration parameters
- Handle edge cases (empty sampling ranges, zero budgets)
- Ensure device consistency across tensors

### 4. Statistical Correctness
- Ensure proper application of statistical bounds
- Handle edge cases in budget computation
- Maintain proper probability interpretations

## File Structure
```
sparse_attention_hub/sparse_attention/research_attention/maskers/sampling/implementations/
├── adaptive_sampling.py  # Main implementation
└── __init__.py          # Update imports
```

## Testing Strategy

### 1. Unit Tests
- Configuration validation
- Edge cases (full masks, empty ranges)
- Statistical properties verification
- Device consistency

### 2. Integration Tests
- End-to-end masker functionality
- Performance benchmarks
- Memory usage validation

### 3. Statistical Tests
- Error bound verification
- Confidence interval validation
- Sampling distribution correctness

## Dependencies
- `scipy.stats.norm` for PPF computation
- `torch` for tensor operations
- Existing Mask utilities

## Future Enhancements
- Dynamic budget adjustment based on attention patterns
- Multi-level adaptive sampling
- Integration with other masker types
- Performance profiling and optimization
```

Perfect! I've created a comprehensive plan for implementing the AdaptiveSamplingMasker. The plan covers:

## Key Highlights of the Plan:

1. **Configuration Structure**: Proper validation for all parameters including `base_rate_sampling`, `epsilon`, `delta`, `init_offset`, and `local_offset`

2. **Algorithm Flow**: 
   - Early exit for full masks
   - Two-phase sampling (base + adaptive)
   - Statistical budget computation using error bounds
   - Proper mask merging

3. **Technical Details**:
   - Uses `scipy.stats.norm.ppf()` for delta_ppf computation
   - Implements the max trick for numerical stability
   - Handles the sampling range `[init_offset: -local_offset]`
   - Proper tensor operations and device handling

4. **Implementation Considerations**:
   - Numerical stability
   - Efficiency optimizations
   - Error handling
   - Statistical correctness

5. **File Structure**: Follows the existing pattern in the codebase

The plan addresses all the requirements from your notes:
- ✅ Extends `SamplingMasker` and `SamplingMaskerConfig`
- ✅ Implements the pseudo-code for `add_mask`
- ✅ Uses `norm.ppf(1-self.delta)` for delta_ppf
- ✅ Handles the sampling range with offsets
- ✅ Implements the statistical budget computation
- ✅ Follows the existing codebase patterns

Would you like me to proceed with implementing this plan, or would you like to iterate on any specific aspects of the design first?

---

**User**

I have added some comments to the plan. list all my comments here and rework the plan

---

**Cursor**

I can see your comments in the plan. Let me list them all and then rework the plan accordingly:

## Your Comments:

1. **`apply_to_tensor` is not defined**: You'll have to use `apply_inv_mask` and sum it up instead
2. **`apply_to_tensor` doesn't exist**: Need to use the index representation of mask to compute row-wise std
3. **`apply_to_tensor` reuse issue**: This function doesn't exist and is being reused for many purposes
4. **Budget equation correction**: The delta-allowable-error equation should be `self.delta_ppf * std_estimate * (#keys - init_offset - local_offset) / sqrt(b)`, not `* sqrt(n)`
5. **Vectorization needed**: The nested loops for creating adaptive sampling mask should be vectorized

Let me rework the plan to address these issues:


```markdown
#### Step 3: Compute Static Denominator
```python
# Apply previous mask to expwts to get static contribution
static_denominator = previous_mask.apply_to_tensor(expwts)  # (b, h, q, 1)
```

->

#### Step 3: Compute Static Denominator
```python
# Apply previous mask to expwts to get static contribution
# Use the sparse representation to compute the sum efficiently
static_denominator = previous_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)
```
```

Let me read the current file to see the exact content:


Now let me read the rest of the file and then create a completely revised version:


Now let me check what methods are actually available in the Mask class to understand how to properly work with it:


Now I have a good understanding of the Mask class methods. Let me create a completely revised plan that addresses all your comments:


```markdown
# AdaptiveSamplingMasker Implementation Plan (Revised)

## Overview
The AdaptiveSamplingMasker is a sophisticated sampling-based masker that adaptively determines sampling budgets based on statistical error bounds. It combines base sampling with adaptive budget allocation to achieve optimal sparsity while maintaining statistical guarantees.

## Algorithm Summary
The masker uses a two-phase approach:
1. **Base Sampling Phase**: Randomly samples a base fraction of positions
2. **Adaptive Budget Phase**: Computes optimal sampling budgets per row based on statistical error bounds (epsilon, delta)

## Configuration Structure

### AdaptiveSamplingMaskerConfig
```python
@dataclass
class AdaptiveSamplingMaskerConfig(SamplingMaskerConfig):
    base_rate_sampling: Union[int, float]  # Base sampling rate (0,1) if float
    epsilon: float  # Error bound (0,1)
    delta: float   # Confidence bound (0,1)
    init_offset: int  # Start index for sampling
    local_offset: int  # End offset for sampling
```

**Validation Rules:**
- `base_rate_sampling`: If float, must be in (0,1); if int, must be positive
- `epsilon`: Must be in (0,1)
- `delta`: Must be in (0,1)
- `init_offset`: Must be non-negative
- `local_offset`: Must be non-negative

## Core Implementation Plan

### 1. Class Structure
```python
@MaskerRegistry.register(AdaptiveSamplingMaskerConfig)
class AdaptiveSamplingMasker(SamplingMasker):
    def __init__(self, config: AdaptiveSamplingMaskerConfig):
        super().__init__(config)
        # Store configuration parameters
        self.base_rate_sampling = config.base_rate_sampling
        self.epsilon = config.epsilon
        self.delta = config.delta
        self.init_offset = config.init_offset
        self.local_offset = config.local_offset
        
        # Pre-compute delta_ppf for efficiency
        self.delta_ppf = norm.ppf(1 - self.delta)  # scipy.stats.norm
```

### 2. Main add_mask Method Algorithm

#### Step 1: Early Exit Check
```python
if previous_mask.is_full_mask():
    return previous_mask
```

#### Step 2: Extract Dimensions and Compute Attention Scores
```python
batch_size, num_heads, seq_len_queries, seq_len_keys = extract_dimensions(keys, queries)
# Compute raw attention scores with max trick for numerical stability
raw_attention_scores = torch.matmul(queries, keys.transpose(-2, -1))
max_scores = torch.max(raw_attention_scores, dim=-1, keepdim=True)[0]
expwts = torch.exp(raw_attention_scores - max_scores)  # (b, h, q, k)
```

#### Step 3: Compute Static Denominator
```python
# Apply previous mask to expwts to get static contribution
# Use apply_inv_mask and sum to get the denominator
static_denominator = previous_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)
```

#### Step 4: Create Base Sampling Mask
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Create base sampling mask using row-wise sampling
num_base_samples = int(self.base_rate_sampling * sampling_range)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 5: Estimate Standard Deviation Using Index Representation
```python
# Use the sparse index representation to compute row-wise std efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices for each row
sampled_values = expwts_2d[indices]  # Shape: (total_sampled_indices,)

# Reshape to get per-row samples: (batch_size * num_heads * seq_len_queries, num_base_samples)
row_sampled_values = []
for i in range(len(ptr) - 1):
    start_idx = ptr[i]
    end_idx = ptr[i + 1]
    row_values = sampled_values[start_idx:end_idx]
    # Pad with zeros if needed to maintain consistent shape
    if len(row_values) < num_base_samples:
        padding = torch.zeros(num_base_samples - len(row_values), device=keys.device, dtype=keys.dtype)
        row_values = torch.cat([row_values, padding])
    row_sampled_values.append(row_values)

row_sampled_values = torch.stack(row_sampled_values)  # (batch_size * num_heads * seq_len_queries, num_base_samples)

# Compute standard deviation per row
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (batch_size * num_heads * seq_len_queries, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

#### Step 6: Compute Sampled Denominator Using Index Representation
```python
# Use the sparse index representation to compute the sum efficiently
sampled_denominator = base_sampling_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)
```

#### Step 7: Estimate Total Denominator
```python
estimated_denominator = static_denominator + sampled_denominator  # (b, h, q, 1)
```

#### Step 8: Compute Adaptive Budgets (Corrected Equation)
```python
# Compute error bounds
epsilon_allowable_error = self.epsilon * estimated_denominator  # (b, h, q, 1)

# Corrected equation: delta_allowable_error = self.delta_ppf * std_estimate * sampling_range / sqrt(b)
# Solving for budget b: epsilon_error = self.delta_ppf * std_estimate * sampling_range / sqrt(b)
# Therefore: b = (self.delta_ppf * std_estimate * sampling_range / epsilon_error)^2
budget_numerator = self.delta_ppf * std_estimate * sampling_range
budget = torch.clamp(
    (budget_numerator / epsilon_allowable_error) ** 2,
    min=1,  # Minimum 1 sample
    max=sampling_range  # Maximum all available positions
).long()  # (b, h, q, 1)
```

#### Step 9: Create Adaptive Sampling Mask (Vectorized)
```python
# Vectorized approach to create adaptive sampling mask
# Create a tensor of all possible indices in the sampling range
all_indices = torch.arange(sampling_range, device=keys.device).unsqueeze(0).unsqueeze(0).unsqueeze(0).expand(
    batch_size, num_heads, seq_len_queries, sampling_range
)

# Create random permutation for each row
# Use different seeds for each batch/head/query to ensure independence
torch.manual_seed(torch.randint(0, 1000000, (1,)).item())
permutations = torch.rand(batch_size, num_heads, seq_len_queries, sampling_range).argsort(dim=-1)

# Select top-k indices based on budget for each row
# Create a mask for valid positions (where permutation < budget)
valid_mask = permutations < budget.unsqueeze(-1)  # (b, h, q, sampling_range)

# Apply the mask to get selected indices
selected_indices = all_indices * valid_mask  # (b, h, q, sampling_range)

# Shift indices by start_idx
selected_indices = selected_indices + start_idx

# Create data tensor with ones for selected positions
adaptive_data = valid_mask.float()  # (b, h, q, sampling_range)

# Create the adaptive mask using row-wise indices
adaptive_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=selected_indices,
    data=adaptive_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 10: Merge and Return
```python
# Merge base sampling mask with adaptive mask
combined_mask = base_sampling_mask.merge_mask(adaptive_mask, inplace=False)
# Merge with previous mask
return previous_mask.merge_mask(combined_mask, inplace=False)
```

## Key Implementation Considerations

### 1. Numerical Stability
- Use max trick for exponential computation
- Handle edge cases where denominators are zero
- Ensure proper dtype handling throughout

### 2. Efficiency Optimizations
- Pre-compute `delta_ppf` in constructor
- Use sparse index representation directly for computations
- Vectorized budget computation and sampling
- Efficient tensor operations for sampling

### 3. Error Handling
- Validate all configuration parameters
- Handle edge cases (empty sampling ranges, zero budgets)
- Ensure device consistency across tensors

### 4. Statistical Correctness
- Ensure proper application of statistical bounds
- Handle edge cases in budget computation
- Maintain proper probability interpretations

## File Structure
```
sparse_attention_hub/sparse_attention/research_attention/maskers/sampling/implementations/
├── adaptive_sampling.py  # Main implementation
└── __init__.py          # Update imports
```

## Testing Strategy

### 1. Unit Tests
- Configuration validation
- Edge cases (full masks, empty ranges)
- Statistical properties verification
- Device consistency

### 2. Integration Tests
- End-to-end masker functionality
- Performance benchmarks
- Memory usage validation

### 3. Statistical Tests
- Error bound verification
- Confidence interval validation
- Sampling distribution correctness

## Dependencies
- `scipy.stats.norm` for PPF computation
- `torch` for tensor operations
- Existing Mask utilities

## Future Enhancements
- Dynamic budget adjustment based on attention patterns
- Multi-level adaptive sampling
- Integration with other masker types
- Performance profiling and optimization
```

Perfect! I've completely revised the plan to address all your comments:

## Summary of Changes Made:

### 1. **Fixed `apply_to_tensor` Issues**
- **Step 3**: Changed from `previous_mask.apply_to_tensor(expwts)` to `previous_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)`
- **Step 6**: Changed from `base_sampling_mask.apply_to_tensor(expwts)` to `base_sampling_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)`

### 2. **Implemented Proper Standard Deviation Computation**
- **Step 5**: Completely rewrote to use the sparse index representation directly
- Uses `get_index_mask()` to get `indices`, `ptr`, and `data`
- Efficiently extracts sampled values using the sparse indices
- Computes row-wise standard deviation without converting to dense representation

### 3. **Corrected Budget Equation**
- **Step 8**: Fixed the equation from `* sqrt(sampling_range)` to `* sampling_range / sqrt(b)`
- The correct equation is: `delta_allowable_error = self.delta_ppf * std_estimate * sampling_range / sqrt(b)`
- Solving for budget: `b = (self.delta_ppf * std_estimate * sampling_range / epsilon_error)^2`

### 4. **Vectorized Adaptive Sampling Mask Creation**
- **Step 9**: Replaced nested loops with vectorized operations
- Uses `torch.rand().argsort()` to create random permutations
- Creates a boolean mask for valid positions based on budget
- Efficiently selects indices using tensor operations
- Much more efficient than the original nested loop approach

## Key Improvements:

1. **Efficiency**: Uses sparse representations directly instead of converting to dense
2. **Correctness**: Fixed the statistical equation for budget computation
3. **Vectorization**: Eliminated nested loops in favor of tensor operations
4. **Memory**: More memory-efficient by avoiding unnecessary dense conversions

The revised plan now properly uses the existing Mask class methods (`apply_inv_mask`, `get_index_mask`) and provides a much more efficient and correct implementation. Would you like me to proceed with implementing this revised plan?

---

**User**

list my comments and rework the plan

---

**Cursor**

I can see your comments in the plan. Let me list them and then rework the plan accordingly:

## Your Comments:

1. **Step 5 - Vectorization**: Use the fact that we have the same number of samples in each row to vectorize the standard deviation computation
2. **Step 9 - Data values**: The data should have value `budget / sampling_range` (i.e., the probability with which it was sampled) instead of just 1.0

Let me rework the plan to address these issues:


```markdown
#### Step 5: Estimate Standard Deviation Using Index Representation # aditya(use the fact that we have same number of samples in each row to vectorize it)
```python
# Use the sparse index representation to compute row-wise std efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices for each row
sampled_values = expwts_2d[indices]  # Shape: (total_sampled_indices,)

# Reshape to get per-row samples: (batch_size * num_heads * seq_len_queries, num_base_samples)
row_sampled_values = []
for i in range(len(ptr) - 1):
    start_idx = ptr[i]
    end_idx = ptr[i + 1]
    row_values = sampled_values[start_idx:end_idx]
    # Pad with zeros if needed to maintain consistent shape
    if len(row_values) < num_base_samples:
        padding = torch.zeros(num_base_samples - len(row_values), device=keys.device, dtype=keys.dtype)
        row_values = torch.cat([row_values, padding])
    row_sampled_values.append(row_values)

row_sampled_values = torch.stack(row_sampled_values)  # (batch_size * num_heads * seq_len_queries, num_base_samples)

# Compute standard deviation per row
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (batch_size * num_heads * seq_len_queries, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

->

#### Step 5: Estimate Standard Deviation Using Index Representation (Vectorized)
```python
# Use the sparse index representation to compute row-wise std efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

# Since we have the same number of samples per row (num_base_samples), we can vectorize
# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices for each row
sampled_values = expwts_2d[indices]  # Shape: (total_sampled_indices,)

# Since each row has exactly num_base_samples, we can reshape directly
# total_rows = batch_size * num_heads * seq_len_queries
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

# Compute standard deviation per row (vectorized)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (total_rows, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```
```

```markdown
# Create data tensor with ones for selected positions
adaptive_data = valid_mask.float()  # (b, h, q, sampling_range) #aditya(the data -- each row should have value budget / sampling_rate , i.e. the probability with which it was sampled)

->

# Create data tensor with sampling probabilities for selected positions
# Each selected position should have value budget / sampling_range (probability of being sampled)
sampling_probabilities = budget.float() / sampling_range  # (b, h, q, 1)
adaptive_data = valid_mask.float() * sampling_probabilities.unsqueeze(-1)  # (b, h, q, sampling_range)
```

Perfect! I've addressed both of your comments:

## Summary of Changes Made:

### 1. **Vectorized Standard Deviation Computation (Step 5)**
- **Before**: Used a loop to process each row individually with padding logic
- **After**: Leveraged the fact that each row has exactly `num_base_samples` to directly reshape the tensor
- **Improvement**: Much more efficient - eliminated the loop and padding logic, using direct tensor reshaping instead

### 2. **Corrected Data Values (Step 9)**
- **Before**: Used `valid_mask.float()` (all selected positions had value 1.0)
- **After**: Used `valid_mask.float() * sampling_probabilities.unsqueeze(-1)` where `sampling_probabilities = budget.float() / sampling_range`
- **Improvement**: Now each selected position has the correct probability value representing how likely it was to be sampled

## Key Benefits:

1. **Performance**: The vectorized standard deviation computation is much faster and more memory efficient
2. **Correctness**: The data values now properly represent sampling probabilities, which is important for the statistical interpretation of the mask
3. **Simplicity**: Eliminated complex loop logic in favor of simple tensor operations

The revised plan now properly handles both the vectorization opportunity and the correct probability assignment for the adaptive sampling mask. Would you like me to proceed with implementing this final version of the plan?

---

**User**

static_denominator = previous_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)

can we have a cheaper implementation of this which leverages the sparse representation of mask?

---

**Cursor**

Yes, absolutely! We can implement a much cheaper version that leverages the sparse representation directly. Let me analyze the current approach and provide a more efficient implementation.


Yes, absolutely! We can implement a much cheaper version that leverages the sparse representation directly. Looking at the current `apply_inv_mask` implementation, I can see it creates a dense tensor and then applies the inverse mask. We can optimize this significantly.

Let me update the plan with a more efficient implementation:


```markdown
#### Step 3: Compute Static Denominator
```python
# Apply previous mask to expwts to get static contribution
# Use apply_inv_mask and sum to get the denominator
static_denominator = previous_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)
```

->

#### Step 3: Compute Static Denominator (Optimized)
```python
# Apply previous mask to expwts to get static contribution
# Use sparse representation directly for efficiency
if previous_mask.is_full_mask():
    # Full mask: sum all expwts
    static_denominator = expwts.sum(dim=-1, keepdim=True)  # (b, h, q, 1)
elif previous_mask.is_empty():
    # Empty mask: no contribution
    static_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                   device=expwts.device, dtype=expwts.dtype)
else:
    # Sparse mask: use sparse representation directly
    indices, ptr, data = previous_mask.get_index_mask()
    
    if indices.numel() == 0:
        # No active indices
        static_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                       device=expwts.device, dtype=expwts.dtype)
    else:
        # Reshape expwts to 1D for indexing
        expwts_flat = expwts.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)
        
        # Extract values at sparse indices and apply inverse mask
        expwts_at_indices = expwts_flat[indices]  # (num_active_indices,)
        inverse_data = 1.0 / data  # (num_active_indices,)
        weighted_expwts = expwts_at_indices * inverse_data  # (num_active_indices,)
        
        # Sum per row using ptr array
        num_rows = batch_size * num_heads * seq_len_queries
        static_denominator = torch.zeros(num_rows, 1, device=expwts.device, dtype=expwts.dtype)
        
        for i in range(num_rows):
            start_idx = ptr[i]
            end_idx = ptr[i + 1]
            if start_idx < end_idx:
                static_denominator[i, 0] = weighted_expwts[start_idx:end_idx].sum()
        
        # Reshape back to original dimensions
        static_denominator = static_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```
```

```markdown
#### Step 6: Compute Sampled Denominator Using Index Representation
```python
# Use the sparse index representation to compute the sum efficiently
sampled_denominator = base_sampling_mask.apply_inv_mask(expwts).sum(dim=-1, keepdim=True)  # (b, h, q, 1)
```

->

#### Step 6: Compute Sampled Denominator Using Index Representation (Optimized)
```python
# Use the sparse index representation to compute the sum efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

if indices.numel() == 0:
    # No active indices
    sampled_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                    device=expwts.device, dtype=expwts.dtype)
else:
    # Reshape expwts to 1D for indexing
    expwts_flat = expwts.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)
    
    # Extract values at sparse indices and apply inverse mask
    expwts_at_indices = expwts_flat[indices]  # (num_active_indices,)
    inverse_data = 1.0 / data  # (num_active_indices,)
    weighted_expwts = expwts_at_indices * inverse_data  # (num_active_indices,)
    
    # Sum per row using ptr array
    num_rows = batch_size * num_heads * seq_len_queries
    sampled_denominator = torch.zeros(num_rows, 1, device=expwts.device, dtype=expwts.dtype)
    
    for i in range(num_rows):
        start_idx = ptr[i]
        end_idx = ptr[i + 1]
        if start_idx < end_idx:
            sampled_denominator[i, 0] = weighted_expwts[start_idx:end_idx].sum()
    
    # Reshape back to original dimensions
    sampled_denominator = sampled_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```
```

Perfect! I've optimized both denominator computations to use the sparse representation directly. Here's what the optimized implementation does:

## Key Optimizations:

### 1. **Avoids Dense Tensor Creation**
- **Before**: `previous_mask.apply_inv_mask(expwts)` creates a full dense tensor
- **After**: Works directly with sparse indices and data

### 2. **Efficient Indexing**
- Flattens `expwts` to 1D for efficient indexing
- Extracts only the values at sparse indices
- Applies inverse mask directly to these values

### 3. **Optimized Summation**
- Uses the `ptr` array to efficiently sum per row
- Avoids creating intermediate dense tensors
- Only processes active indices

### 4. **Special Case Handling**
- **Full mask**: Direct sum of all `expwts`
- **Empty mask**: Returns zero tensor
- **No active indices**: Returns zero tensor

## Performance Benefits:

1. **Memory**: No need to create dense tensors of size `(b, h, q, k)`
2. **Computation**: Only processes non-zero elements
3. **Scalability**: Performance scales with sparsity, not total size
4. **Efficiency**: Direct sparse operations without conversions

## Algorithm Flow:
1. Get sparse representation (`indices`, `ptr`, `data`)
2. Extract `expwts` values at sparse indices
3. Apply inverse mask: `expwts_at_indices * (1.0 / data)`
4. Sum per row using `ptr` array
5. Reshape to original dimensions

This optimization is especially beneficial when:
- The mask is very sparse (few active positions)
- The sequence length is large
- Memory is constrained

The optimized version should be significantly faster and more memory-efficient than the original approach!

---

**User**

Can we avoid using for loop without goint to the dense mask ? can we use scatter functions?

---

**Cursor**

Absolutely! We can use scatter functions to eliminate the for loop while still working with the sparse representation. Let me update the plan to use `torch.scatter_add_` for efficient vectorized operations.


```markdown
        # Sum per row using ptr array
        num_rows = batch_size * num_heads * seq_len_queries
        static_denominator = torch.zeros(num_rows, 1, device=expwts.device, dtype=expwts.dtype)
        
        for i in range(num_rows):
            start_idx = ptr[i]
            end_idx = ptr[i + 1]
            if start_idx < end_idx:
                static_denominator[i, 0] = weighted_expwts[start_idx:end_idx].sum()
        
        # Reshape back to original dimensions
        static_denominator = static_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)

->

        # Use scatter_add_ for vectorized row-wise summation
        num_rows = batch_size * num_heads * seq_len_queries
        
        # Create row indices for each sparse element
        # indices are flattened, so row_idx = indices // seq_len_keys
        row_indices = indices // seq_len_keys  # (num_active_indices,)
        
        # Create output tensor for scatter operation
        static_denominator = torch.zeros(num_rows, device=expwts.device, dtype=expwts.dtype)
        
        # Use scatter_add_ to sum weighted values per row
        static_denominator.scatter_add_(0, row_indices, weighted_expwts)
        
        # Reshape back to original dimensions
        static_denominator = static_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

```markdown
    # Sum per row using ptr array
    num_rows = batch_size * num_heads * seq_len_queries
    sampled_denominator = torch.zeros(num_rows, 1, device=expwts.device, dtype=expwts.dtype)
    
    for i in range(num_rows):
        start_idx = ptr[i]
        end_idx = ptr[i + 1]
        if start_idx < end_idx:
            sampled_denominator[i, 0] = weighted_expwts[start_idx:end_idx].sum()
    
    # Reshape back to original dimensions
    sampled_denominator = sampled_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)

->

    # Use scatter_add_ for vectorized row-wise summation
    num_rows = batch_size * num_heads * seq_len_queries
    
    # Create row indices for each sparse element
    # indices are flattened, so row_idx = indices // seq_len_keys
    row_indices = indices // seq_len_keys  # (num_active_indices,)
    
    # Create output tensor for scatter operation
    sampled_denominator = torch.zeros(num_rows, device=expwts.device, dtype=expwts.dtype)
    
    # Use scatter_add_ to sum weighted values per row
    sampled_denominator.scatter_add_(0, row_indices, weighted_expwts)
    
    # Reshape back to original dimensions
    sampled_denominator = sampled_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

Perfect! I've eliminated the for loops and replaced them with efficient `torch.scatter_add_` operations. Here's what the optimized implementation does:

## Key Improvements:

### 1. **Vectorized Row Index Computation**
- **Before**: Used `ptr` array with loops to find row boundaries
- **After**: Direct computation: `row_indices = indices // seq_len_keys`
- **Benefit**: Single vectorized operation instead of loop

### 2. **Scatter-Based Summation**
- **Before**: Loop through each row and sum manually
- **After**: `scatter_add_(0, row_indices, weighted_expwts)`
- **Benefit**: Highly optimized CUDA operation, no Python loops

### 3. **Memory Efficiency**
- **Before**: Created 2D tensor `(num_rows, 1)`
- **After**: Creates 1D tensor `(num_rows,)`
- **Benefit**: Slightly less memory usage

## How `scatter_add_` Works:

```python
# scatter_add_(dim, index, src)
static_denominator.scatter_add_(0, row_indices, weighted_expwts)
```

- **`dim=0`**: Add along the first dimension (rows)
- **`row_indices`**: Specifies which row each value belongs to
- **`weighted_expwts`**: The values to add to each row
- **Result**: Automatically sums all values that belong to the same row

## Performance Benefits:

1. **Vectorization**: No Python loops, pure tensor operations
2. **CUDA Optimization**: `scatter_add_` is highly optimized on GPU
3. **Memory Access**: Efficient memory access patterns
4. **Scalability**: Performance scales well with sparsity

## Example:
```python
# If we have:
# indices = [0, 2, 5, 8, 10, 15]  # sparse indices
# seq_len_keys = 4
# Then:
# row_indices = [0, 0, 1, 2, 2, 3]  # which row each index belongs to
# weighted_expwts = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]
# Result: [0.3, 0.3, 0.9, 0.6]  # sums per row
```

This approach is much more efficient than the loop-based version and leverages PyTorch's optimized scatter operations!

```python
# scatter_add_(dim, index, src)
static_denominator.scatter_add_(0, row_indices, weighted_expwts)
```

```python
# If we have:
# indices = [0, 2, 5, 8, 10, 15]  # sparse indices
# seq_len_keys = 4
# Then:
# row_indices = [0, 0, 1, 2, 2, 3]  # which row each index belongs to
# weighted_expwts = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]
# Result: [0.3, 0.3, 0.9, 0.6]  # sums per row
```

---

**User**

create this function as a utility in mask_attention_utils. call this 
apply_inv_mask_sum(input_tensor : torch.Tensor , mask: Mask)

---

**Cursor**

I'll create a utility function `apply_inv_mask_sum` in the `mask_attention_utils.py` file that efficiently computes the sum of applying the inverse mask to an input tensor using the sparse representation and scatter operations.


Now let me add the `apply_inv_mask_sum` utility function to the file:


```python
from .mask import Mask


def _compute_masked_exp_attention_weights(

->

from .mask import Mask


def apply_inv_mask_sum(input_tensor: torch.Tensor, mask: Mask) -> torch.Tensor:
    """Apply inverse mask to input tensor and sum along the last dimension.
    
    This function efficiently computes the sum of applying the inverse mask to an input tensor
    using sparse representation and scatter operations, avoiding the need to create dense tensors.
    
    Args:
        input_tensor: Input tensor of shape (..., n) where n is the last dimension
        mask: Mask object to apply inverse mask with
        
    Returns:
        Sum tensor of shape (..., 1) with the last dimension reduced
        
    Note:
        - For full masks: returns sum of all input values
        - For empty masks: returns zero tensor
        - For sparse masks: efficiently computes sum using sparse operations
    """
    if input_tensor.shape != mask.shape:
        raise ValueError(
            f"input_tensor.shape must be {mask.shape}, got {input_tensor.shape}"
        )
    
    # Handle special cases
    if mask.is_full_mask():
        # Full mask: sum all input values
        return input_tensor.sum(dim=-1, keepdim=True)
    elif mask.is_empty():
        # Empty mask: return zero tensor
        return torch.zeros(
            input_tensor.shape[:-1] + (1,),
            device=input_tensor.device,
            dtype=input_tensor.dtype
        )
    
    # Get sparse representation
    indices, ptr, data = mask.get_index_mask()
    
    if indices.numel() == 0:
        # No active indices: return zero tensor
        return torch.zeros(
            input_tensor.shape[:-1] + (1,),
            device=input_tensor.device,
            dtype=input_tensor.dtype
        )
    
    # Reshape input tensor to 1D for indexing
    input_flat = input_tensor.view(-1)  # (total_elements,)
    
    # Extract values at sparse indices and apply inverse mask
    input_at_indices = input_flat[indices]  # (num_active_indices,)
    inverse_data = 1.0 / data  # (num_active_indices,)
    weighted_input = input_at_indices * inverse_data  # (num_active_indices,)
    
    # Use scatter_add_ for vectorized row-wise summation
    num_rows = int(torch.prod(torch.tensor(input_tensor.shape[:-1])))
    
    # Create row indices for each sparse element
    # indices are flattened, so row_idx = indices // input_tensor.shape[-1]
    seq_len_last = input_tensor.shape[-1]
    row_indices = indices // seq_len_last  # (num_active_indices,)
    
    # Create output tensor for scatter operation
    result = torch.zeros(num_rows, device=input_tensor.device, dtype=input_tensor.dtype)
    
    # Use scatter_add_ to sum weighted values per row
    result.scatter_add_(0, row_indices, weighted_input)
    
    # Reshape back to original dimensions (except last dimension becomes 1)
    result = result.view(input_tensor.shape[:-1] + (1,))
    
    return result


def _compute_masked_exp_attention_weights(
```

Now let me update the plan to use this new utility function:


```markdown
#### Step 3: Compute Static Denominator (Optimized)
```python
# Apply previous mask to expwts to get static contribution
# Use sparse representation directly for efficiency
if previous_mask.is_full_mask():
    # Full mask: sum all expwts
    static_denominator = expwts.sum(dim=-1, keepdim=True)  # (b, h, q, 1)
elif previous_mask.is_empty():
    # Empty mask: no contribution
    static_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                   device=expwts.device, dtype=expwts.dtype)
else:
    # Sparse mask: use sparse representation directly
    indices, ptr, data = previous_mask.get_index_mask()
    
    if indices.numel() == 0:
        # No active indices
        static_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                       device=expwts.device, dtype=expwts.dtype)
    else:
        # Reshape expwts to 1D for indexing
        expwts_flat = expwts.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)
        
        # Extract values at sparse indices and apply inverse mask
        expwts_at_indices = expwts_flat[indices]  # (num_active_indices,)
        inverse_data = 1.0 / data  # (num_active_indices,)
        weighted_expwts = expwts_at_indices * inverse_data  # (num_active_indices,)
        
        # Use scatter_add_ for vectorized row-wise summation
        num_rows = batch_size * num_heads * seq_len_queries
        
        # Create row indices for each sparse element
        # indices are flattened, so row_idx = indices // seq_len_keys
        row_indices = indices // seq_len_keys  # (num_active_indices,)
        
        # Create output tensor for scatter operation
        static_denominator = torch.zeros(num_rows, device=expwts.device, dtype=expwts.dtype)
        
        # Use scatter_add_ to sum weighted values per row
        static_denominator.scatter_add_(0, row_indices, weighted_expwts)
        
        # Reshape back to original dimensions
        static_denominator = static_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

->

#### Step 3: Compute Static Denominator (Using Utility Function)
```python
# Apply previous mask to expwts to get static contribution
# Use the optimized utility function
from sparse_attention_hub.sparse_attention.utils.mask_attention_utils import apply_inv_mask_sum

static_denominator = apply_inv_mask_sum(expwts, previous_mask)  # (b, h, q, 1)
```
```

```markdown
#### Step 6: Compute Sampled Denominator Using Index Representation (Optimized)
```python
# Use the sparse index representation to compute the sum efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

if indices.numel() == 0:
    # No active indices
    sampled_denominator = torch.zeros(batch_size, num_heads, seq_len_queries, 1, 
                                    device=expwts.device, dtype=expwts.dtype)
else:
    # Reshape expwts to 1D for indexing
    expwts_flat = expwts.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)
    
    # Extract values at sparse indices and apply inverse mask
    expwts_at_indices = expwts_flat[indices]  # (num_active_indices,)
    inverse_data = 1.0 / data  # (num_active_indices,)
    weighted_expwts = expwts_at_indices * inverse_data  # (num_active_indices,)
    
    # Use scatter_add_ for vectorized row-wise summation
    num_rows = batch_size * num_heads * seq_len_queries
    
    # Create row indices for each sparse element
    # indices are flattened, so row_idx = indices // seq_len_keys
    row_indices = indices // seq_len_keys  # (num_active_indices,)
    
    # Create output tensor for scatter operation
    sampled_denominator = torch.zeros(num_rows, device=expwts.device, dtype=expwts.dtype)
    
    # Use scatter_add_ to sum weighted values per row
    sampled_denominator.scatter_add_(0, row_indices, weighted_expwts)
    
    # Reshape back to original dimensions
    sampled_denominator = sampled_denominator.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

->

#### Step 6: Compute Sampled Denominator Using Utility Function
```python
# Use the optimized utility function for base sampling mask
sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)  # (b, h, q, 1)
```
```

Perfect! I've created the `apply_inv_mask_sum` utility function and updated the plan to use it. Here's what I've implemented:

## New Utility Function: `apply_inv_mask_sum`

### **Location**: `sparse_attention_hub/sparse_attention/utils/mask_attention_utils.py`

### **Function Signature**:
```python
def apply_inv_mask_sum(input_tensor: torch.Tensor, mask: Mask) -> torch.Tensor:
```

### **Key Features**:

1. **Efficient Sparse Operations**: Uses sparse representation directly without creating dense tensors
2. **Vectorized Computation**: Uses `torch.scatter_add_` for efficient row-wise summation
3. **Special Case Handling**: 
   - Full masks: Direct sum of all input values
   - Empty masks: Returns zero tensor
   - No active indices: Returns zero tensor
4. **Generic Design**: Works with any tensor shape `(..., n)`
5. **Proper Error Handling**: Validates input tensor shape matches mask shape

### **Algorithm**:
1. Handle special cases (full/empty masks)
2. Get sparse representation (`indices`, `ptr`, `data`)
3. Extract input values at sparse indices
4. Apply inverse mask: `input_at_indices * (1.0 / data)`
5. Use `scatter_add_` for vectorized row-wise summation
6. Reshape to output format `(..., 1)`

### **Usage in Plan**:
The plan now uses this utility function for both:
- **Step 3**: `static_denominator = apply_inv_mask_sum(expwts, previous_mask)`
- **Step 6**: `sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)`

### **Benefits**:
1. **Reusability**: Can be used by other maskers and utilities
2. **Performance**: Highly optimized sparse operations
3. **Maintainability**: Centralized logic for inverse mask summation
4. **Consistency**: Ensures all maskers use the same efficient implementation

The utility function is now ready to be used in the AdaptiveSamplingMasker implementation and can be reused by other maskers that need similar functionality!

```python
def apply_inv_mask_sum(input_tensor: torch.Tensor, mask: Mask) -> torch.Tensor:
```

---

**User**

use this new function in the plan

---

**Cursor**

I can see that the plan has already been updated to use the new `apply_inv_mask_sum` utility function! Let me show you the current state of the plan with the utility function usage:


Perfect! The plan is already updated to use the new `apply_inv_mask_sum` utility function. Here's how it's being used:

## Current Usage in the Plan:

### **Step 3: Compute Static Denominator**
```python
# Apply previous mask to expwts to get static contribution
# Use the optimized utility function
from sparse_attention_hub.sparse_attention.utils.mask_attention_utils import apply_inv_mask_sum

static_denominator = apply_inv_mask_sum(expwts, previous_mask)  # (b, h, q, 1)
```

### **Step 6: Compute Sampled Denominator**
```python
# Use the optimized utility function for base sampling mask
sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)  # (b, h, q, 1)
```

## Benefits of Using the Utility Function:

1. **Cleaner Code**: Replaced ~20 lines of complex sparse operations with a single function call
2. **Reusability**: The same efficient implementation can be used by other maskers
3. **Maintainability**: Centralized logic for inverse mask summation
4. **Performance**: Uses the optimized scatter-based implementation
5. **Consistency**: Ensures all maskers use the same efficient approach

## Key Features of the Implementation:

- **Efficient**: Uses sparse representation directly with `scatter_add_`
- **Robust**: Handles all edge cases (full masks, empty masks, no active indices)
- **Generic**: Works with any tensor shape `(..., n)`
- **Optimized**: No dense tensor creation, pure sparse operations

The plan is now much cleaner and more maintainable while maintaining the same high performance! The utility function encapsulates all the complex sparse operations, making the main algorithm easier to understand and implement.

```python
# Apply previous mask to expwts to get static contribution
# Use the optimized utility function
from sparse_attention_hub.sparse_attention.utils.mask_attention_utils import apply_inv_mask_sum

static_denominator = apply_inv_mask_sum(expwts, previous_mask)  # (b, h, q, 1)
```

```python
# Use the optimized utility function for base sampling mask
sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)  # (b, h, q, 1)
```

---

**User**

Look at my comments and rework the plan

---

**Cursor**

I don't see any new comments in your message. Could you please share the comments you'd like me to address? You can either:

1. Add comments directly to the plan file and let me know, or
2. List the comments here so I can review and rework the plan accordingly

Once I see your comments, I'll be happy to rework the plan to address them!

---

**User**

#aditya( can we combine step 4 and step 5 into a single algorithm -- without creating the mask first)

---

**Cursor**

Absolutely! We can combine steps 4 and 5 into a single algorithm that directly computes the standard deviation without creating the mask first. This will be more efficient. Let me rework the plan:


```markdown
#### Step 4: Create Base Sampling Mask
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Create base sampling mask using row-wise sampling
num_base_samples = int(self.base_rate_sampling * sampling_range)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 5: Estimate Standard Deviation Using Index Representation (Vectorized)
```python
# Use the sparse index representation to compute row-wise std efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

# Since we have the same number of samples per row (num_base_samples), we can vectorize
# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices for each row
sampled_values = expwts_2d[indices]  # Shape: (total_sampled_indices,)

# Since each row has exactly num_base_samples, we can reshape directly
# total_rows = batch_size * num_heads * seq_len_queries
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

# Compute standard deviation per row (vectorized)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (total_rows, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

->

#### Step 4: Create Base Sampling Indices and Estimate Standard Deviation (Combined)
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Create base sampling indices directly (without creating mask first)
num_base_samples = int(self.base_rate_sampling * sampling_range)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)

# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices directly
# Flatten the row_wise_idx for indexing
flat_row_wise_idx = base_row_wise_idx.view(-1)  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
flat_expwts = expwts_2d.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)

# Extract sampled values using advanced indexing
sampled_values = flat_expwts[flat_row_wise_idx]  # (batch_size * num_heads * seq_len_queries * num_base_samples,)

# Reshape to get per-row samples for std computation
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

# Compute standard deviation per row (vectorized)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (total_rows, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)

# Now create the base sampling mask for later use
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```
```

Let me read the current file to see the exact content:


I can see there are two comments in the plan. Let me address both:

1. **Combine steps 4 and 5**: Create base sampling indices and estimate std without creating the mask first
2. **Handle int vs float for base_rate_sampling**: If int, use as direct budget; if float, multiply by sampling_range

Let me rework the plan:


```markdown
#### Step 4: Create Base Sampling Mask #aditya( can we combine step 4 and step 5 into a single algorithm -- without creating the mask first)
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Create base sampling mask using row-wise sampling
#aditya(if self.base_rate_sampling is int, then it defines the budget directly -- if it is float then it needs to be evaluated as below)
num_base_samples = int(self.base_rate_sampling * sampling_range)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 5: Estimate Standard Deviation Using Index Representation (Vectorized)
```python
# Use the sparse index representation to compute row-wise std efficiently
indices, ptr, data = base_sampling_mask.get_index_mask()

# Since we have the same number of samples per row (num_base_samples), we can vectorize
# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices for each row
sampled_values = expwts_2d[indices]  # Shape: (total_sampled_indices,)

# Since each row has exactly num_base_samples, we can reshape directly
# total_rows = batch_size * num_heads * seq_len_queries
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

# Compute standard deviation per row (vectorized)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (total_rows, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)
```

->

#### Step 4: Create Base Sampling Indices and Estimate Standard Deviation (Combined)
```python
# Determine sampling range
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Handle base_rate_sampling: if int, use as direct budget; if float, multiply by sampling_range
if isinstance(self.base_rate_sampling, int):
    num_base_samples = self.base_rate_sampling
else:
    num_base_samples = int(self.base_rate_sampling * sampling_range)

# Create base sampling indices directly (without creating mask first)
base_row_wise_idx = torch.randint(
    low=start_idx, 
    high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)

# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices directly using advanced indexing
# Flatten the row_wise_idx for indexing
flat_row_wise_idx = base_row_wise_idx.view(-1)  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
flat_expwts = expwts_2d.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)

# Extract sampled values using advanced indexing
sampled_values = flat_expwts[flat_row_wise_idx]  # (batch_size * num_heads * seq_len_queries * num_base_samples,)

# Reshape to get per-row samples for std computation
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

# Compute standard deviation per row (vectorized)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)  # (total_rows, 1)

# Reshape back to original dimensions
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)  # (b, h, q, 1)

# Now create the base sampling mask for later use (Step 6)
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```
```

Now I need to update the step numbers since we combined steps 4 and 5:


```markdown
#### Step 6: Compute Sampled Denominator Using Utility Function

->

#### Step 5: Compute Sampled Denominator Using Utility Function
```

```markdown
#### Step 7: Estimate Total Denominator

->

#### Step 6: Estimate Total Denominator
```

```markdown
#### Step 8: Compute Adaptive Budgets (Corrected Equation)

->

#### Step 7: Compute Adaptive Budgets (Corrected Equation)
```

```markdown
#### Step 9: Create Adaptive Sampling Mask (Vectorized)

->

#### Step 8: Create Adaptive Sampling Mask (Vectorized)
```

```markdown
#### Step 10: Merge and Return

->

#### Step 9: Merge and Return
```

Perfect! I've successfully reworked the plan to address your comments:

## Key Changes Made:

### 1. **Combined Steps 4 and 5 into a Single Algorithm**
- **Before**: Created mask first, then extracted indices to compute std
- **After**: Create indices directly, compute std immediately, then create mask for later use
- **Benefit**: More efficient - avoids creating mask just to extract indices

### 2. **Handled int vs float for base_rate_sampling**
- **Before**: Always multiplied by sampling_range
- **After**: 
  - If `int`: Use as direct budget (`num_base_samples = self.base_rate_sampling`)
  - If `float`: Multiply by sampling_range (`num_base_samples = int(self.base_rate_sampling * sampling_range)`)

### 3. **Updated Step Numbers**
- Combined steps 4 and 5 into a single step
- Renumbered all subsequent steps (5→9 became 5→9)

## Algorithm Flow Now:

1. **Step 1**: Early exit check
2. **Step 2**: Extract dimensions and compute attention scores
3. **Step 3**: Compute static denominator using utility function
4. **Step 4**: Create base sampling indices + estimate std (combined)
5. **Step 5**: Compute sampled denominator using utility function
6. **Step 6**: Estimate total denominator
7. **Step 7**: Compute adaptive budgets
8. **Step 8**: Create adaptive sampling mask
9. **Step 9**: Merge and return

## Benefits of the Combined Approach:

1. **Efficiency**: No unnecessary mask creation for std computation
2. **Memory**: Reduced memory usage by avoiding intermediate mask
3. **Clarity**: More logical flow - compute std from indices, then create mask
4. **Flexibility**: Proper handling of int vs float base_rate_sampling

The plan is now more efficient and addresses both of your comments!

---

**User**

Is this piece of code correct? I dont see any row adjustment while creating flat_row_wise_idx 

---

**Cursor**

You're absolutely right! There's a critical issue with the row adjustment in the current code. When we flatten `base_row_wise_idx`, we lose the row information, so the indices don't correspond to the correct rows in the flattened `expwts` tensor.

Let me fix this:


```markdown
# Extract values at the sampled indices directly using advanced indexing
# Flatten the row_wise_idx for indexing
flat_row_wise_idx = base_row_wise_idx.view(-1)  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
flat_expwts = expwts_2d.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)

# Extract sampled values using advanced indexing
sampled_values = flat_expwts[flat_row_wise_idx]  # (batch_size * num_heads * seq_len_queries * num_base_samples,)

->

# Extract values at the sampled indices directly using advanced indexing
# We need to adjust indices for each row to account for the flattened structure
# Create row offsets for each position in the flattened tensor
row_offsets = torch.arange(total_rows, device=keys.device).unsqueeze(1) * seq_len_keys  # (total_rows, 1)

# Adjust the row_wise_idx to account for row offsets
adjusted_row_wise_idx = base_row_wise_idx + row_offsets.unsqueeze(-1)  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for indexing
flat_adjusted_indices = adjusted_row_wise_idx.view(-1)  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
flat_expwts = expwts_2d.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)

# Extract sampled values using advanced indexing
sampled_values = flat_expwts[flat_adjusted_indices]  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
```

Perfect! You caught a critical bug. The issue was that when we flattened `base_row_wise_idx`, the indices were relative to each row (0 to seq_len_keys-1), but when we flattened `expwts_2d`, we needed to account for the row offsets.

## The Problem:
- `base_row_wise_idx` contains indices like `[0, 2, 5]` for each row
- But in the flattened `expwts_2d`, row 0 starts at index 0, row 1 starts at index `seq_len_keys`, row 2 starts at index `2 * seq_len_keys`, etc.
- Without adjustment, we'd be indexing into the wrong rows!

## The Fix:
1. **Create row offsets**: `row_offsets = torch.arange(total_rows) * seq_len_keys`
2. **Adjust indices**: `adjusted_row_wise_idx = base_row_wise_idx + row_offsets.unsqueeze(-1)`
3. **Flatten and index**: Now the indices correctly point to the right positions in the flattened tensor

## Example:
```python
# If seq_len_keys = 4 and we have 3 rows:
# Row 0: indices [0, 2] → adjusted [0, 2]
# Row 1: indices [1, 3] → adjusted [5, 7]  (4 + [1, 3])
# Row 2: indices [0, 1] → adjusted [8, 9]  (8 + [0, 1])
```

This ensures that each row's sampled indices correctly map to the corresponding positions in the flattened `expwts` tensor. Thank you for catching this important issue!

```python
# If seq_len_keys = 4 and we have 3 rows:
# Row 0: indices [0, 2] → adjusted [0, 2]
# Row 1: indices [1, 3] → adjusted [5, 7]  (4 + [1, 3])
# Row 2: indices [0, 1] → adjusted [8, 9]  (8 + [0, 1])
```

---

**User**

Can we use torch indexing to achieve this?

---

**Cursor**

Absolutely! We can use PyTorch's advanced indexing to achieve this more elegantly without manually calculating row offsets. Let me update the code:


```markdown
# Extract values at the sampled indices directly using advanced indexing
# We need to adjust indices for each row to account for the flattened structure
# Create row offsets for each position in the flattened tensor
row_offsets = torch.arange(total_rows, device=keys.device).unsqueeze(1) * seq_len_keys  # (total_rows, 1)

# Adjust the row_wise_idx to account for row offsets
adjusted_row_wise_idx = base_row_wise_idx + row_offsets.unsqueeze(-1)  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for indexing
flat_adjusted_indices = adjusted_row_wise_idx.view(-1)  # (batch_size * num_heads * seq_len_queries * num_base_samples,)
flat_expwts = expwts_2d.view(-1)  # (batch_size * num_heads * seq_len_queries * seq_len_keys,)

# Extract sampled values using advanced indexing
sampled_values = flat_expwts[flat_adjusted_indices]  # (batch_size * num_heads * seq_len_queries * num_base_samples,)

->

# Extract values at the sampled indices using advanced indexing
# Use torch.gather with proper indexing
# Create row indices for each position
row_indices = torch.arange(batch_size, device=keys.device).unsqueeze(1).unsqueeze(1).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)
head_indices = torch.arange(num_heads, device=keys.device).unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)
query_indices = torch.arange(seq_len_queries, device=keys.device).unsqueeze(0).unsqueeze(0).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)

# Use advanced indexing to extract values directly
sampled_values = expwts[row_indices, head_indices, query_indices, base_row_wise_idx]  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for std computation
sampled_values = sampled_values.view(-1, num_base_samples)  # (total_rows, num_base_samples)
```

Actually, let me simplify this even further using `torch.gather` which is more elegant:


```markdown
# Extract values at the sampled indices using advanced indexing
# Use torch.gather with proper indexing
# Create row indices for each position
row_indices = torch.arange(batch_size, device=keys.device).unsqueeze(1).unsqueeze(1).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)
head_indices = torch.arange(num_heads, device=keys.device).unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)
query_indices = torch.arange(seq_len_queries, device=keys.device).unsqueeze(0).unsqueeze(0).unsqueeze(1).expand(
    batch_size, num_heads, seq_len_queries, num_base_samples
)

# Use advanced indexing to extract values directly
sampled_values = expwts[row_indices, head_indices, query_indices, base_row_wise_idx]  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for std computation
sampled_values = sampled_values.view(-1, num_base_samples)  # (total_rows, num_base_samples)

->

# Extract values at the sampled indices using torch.gather
# Gather along the last dimension (seq_len_keys) using the sampled indices
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for std computation
sampled_values = sampled_values.view(-1, num_base_samples)  # (total_rows, num_base_samples)
```

Perfect! Now the code is much cleaner and more efficient. Here's what `torch.gather` does:

## How `torch.gather` Works:

```python
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)
```

- **`expwts`**: Source tensor of shape `(batch_size, num_heads, seq_len_queries, seq_len_keys)`
- **`dim=-1`**: Gather along the last dimension (seq_len_keys)
- **`base_row_wise_idx`**: Index tensor of shape `(batch_size, num_heads, seq_len_queries, num_base_samples)`
- **Result**: Tensor of shape `(batch_size, num_heads, seq_len_queries, num_base_samples)`

## Benefits of Using `torch.gather`:

1. **Automatic Broadcasting**: PyTorch automatically handles the broadcasting of indices across all other dimensions
2. **No Manual Index Creation**: No need to create row/head/query indices manually
3. **More Efficient**: Optimized CUDA operation
4. **Cleaner Code**: Single line instead of multiple index calculations
5. **Less Error-Prone**: No risk of manual indexing mistakes

## Example:
```python
# If expwts has shape (2, 3, 4, 5) and base_row_wise_idx has shape (2, 3, 4, 2)
# torch.gather will automatically:
# - For each (batch, head, query) position
# - Extract the values at the indices specified in base_row_wise_idx[batch, head, query, :]
# - Result: (2, 3, 4, 2) tensor with the gathered values
```

This is much more elegant and efficient than the manual indexing approach!

```python
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)
```

```python
# If expwts has shape (2, 3, 4, 5) and base_row_wise_idx has shape (2, 3, 4, 2)
# torch.gather will automatically:
# - For each (batch, head, query) position
# - Extract the values at the indices specified in base_row_wise_idx[batch, head, query, :]
# - Result: (2, 3, 4, 2) tensor with the gathered values
```

---

**User**

cleanup unncessary code 

---

**Cursor**

You're right! Let me clean up the unnecessary code in the plan:


```markdown
# Reshape expwts to 2D for easier indexing: (batch_size * num_heads * seq_len_queries, seq_len_keys)
expwts_2d = expwts.view(-1, seq_len_keys)

# Extract values at the sampled indices using torch.gather
# Gather along the last dimension (seq_len_keys) using the sampled indices
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for std computation
sampled_values = sampled_values.view(-1, num_base_samples)  # (total_rows, num_base_samples)

# Reshape to get per-row samples for std computation
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)

->

# Extract values at the sampled indices using torch.gather
# Gather along the last dimension (seq_len_keys) using the sampled indices
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)  # (batch_size, num_heads, seq_len_queries, num_base_samples)

# Flatten for std computation
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)  # (total_rows, num_base_samples)
```

Perfect! I've cleaned up the unnecessary code:

## Removed:
1. **`expwts_2d`**: No longer needed since we use `torch.gather` directly on the original tensor
2. **Redundant reshape**: Removed the intermediate `sampled_values.view(-1, num_base_samples)` since we can do it directly
3. **Duplicate comment**: Removed redundant comment about reshaping

## What's Left:
- Direct `torch.gather` operation on `expwts`
- Single reshape to get `row_sampled_values` for std computation
- Clean, efficient code flow

The code is now much cleaner and more efficient without any unnecessary intermediate steps!

---

**User**

Can we just create this mask in the following manner
we will use from_idx construction
1. budgets :reshape to  (num_rows, -1) 
2. total_elements = budgets.sum().item()
2. ptr = use budgets to define this
3. idx_in_row = random [init_offset, #keys - local_offset]  of shape (total_elements,)
4. row_id = torch.repeat_interleave(torch.arange(len(budgets)), budgets)
5. idx_global = idx_in_row + row_id * #keys 
6. data_global = (budgets / sample_range)[row_id]

---

**Cursor**

Absolutely! That's a much more efficient approach using the sparse index construction directly. Let me update the plan to use this method:


```markdown
#### Step 8: Create Adaptive Sampling Mask (Vectorized)
```python
# Vectorized approach to create adaptive sampling mask
# Create a tensor of all possible indices in the sampling range
all_indices = torch.arange(sampling_range, device=keys.device).unsqueeze(0).unsqueeze(0).unsqueeze(0).expand(
    batch_size, num_heads, seq_len_queries, sampling_range
)

# Create random permutation for each row
# Use different seeds for each batch/head/query to ensure independence
torch.manual_seed(torch.randint(0, 1000000, (1,)).item())
permutations = torch.rand(batch_size, num_heads, seq_len_queries, sampling_range).argsort(dim=-1)

# Select top-k indices based on budget for each row
# Create a mask for valid positions (where permutation < budget)
valid_mask = permutations < budget.unsqueeze(-1)  # (b, h, q, sampling_range)

# Apply the mask to get selected indices
selected_indices = all_indices * valid_mask  # (b, h, q, sampling_range)

# Shift indices by start_idx
selected_indices = selected_indices + start_idx

# Create data tensor with sampling probabilities for selected positions
# Each selected position should have value budget / sampling_range (probability of being sampled)
sampling_probabilities = budget.float() / sampling_range  # (b, h, q, 1)
adaptive_data = valid_mask.float() * sampling_probabilities.unsqueeze(-1)  # (b, h, q, sampling_range)

# Create the adaptive mask using row-wise indices
adaptive_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=selected_indices,
    data=adaptive_data,
    type="index",
    dtype=previous_mask.dtype
)
```

->

#### Step 8: Create Adaptive Sampling Mask (Direct Sparse Construction)
```python
# Reshape budget to (num_rows, 1) for easier processing
num_rows = batch_size * num_heads * seq_len_queries
budgets_flat = budget.view(num_rows)  # (num_rows,)

# Calculate total number of elements to sample
total_elements = budgets_flat.sum().item()

# Create ptr array using cumulative sum of budgets
ptr = torch.cat([
    torch.zeros(1, dtype=torch.long, device=keys.device),
    torch.cumsum(budgets_flat, dim=0)
])  # (num_rows + 1,)

# Generate random indices within sampling range for each element
idx_in_row = torch.randint(
    low=start_idx,
    high=end_idx,
    size=(total_elements,),
    device=keys.device,
    dtype=torch.long
)  # (total_elements,)

# Create row indices by repeating each row index according to its budget
row_id = torch.repeat_interleave(torch.arange(num_rows, device=keys.device), budgets_flat)  # (total_elements,)

# Calculate global indices
idx_global = idx_in_row + row_id * seq_len_keys  # (total_elements,)

# Calculate sampling probabilities for each element
sampling_probabilities = budgets_flat / sampling_range  # (num_rows,)
data_global = sampling_probabilities[row_id]  # (total_elements,)

# Create the adaptive mask directly using sparse index construction
adaptive_mask = Mask.create_mask_from_indices(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    indices=idx_global,
    ptr=ptr,
    data=data_global,
    dtype=previous_mask.dtype
)
```
```

Perfect! This is a much more efficient approach. Here's what the new implementation does:

## Key Improvements:

### 1. **Direct Sparse Construction**
- **Before**: Created dense tensors and then converted to sparse
- **After**: Directly constructs sparse representation using `create_mask_from_indices`

### 2. **Efficient Memory Usage**
- **Before**: Created tensors of size `(b, h, q, sampling_range)` 
- **After**: Only creates tensors of size `(total_elements,)` where `total_elements = sum(budgets)`

### 3. **Simplified Algorithm**
- **Before**: Complex permutation-based selection with masking
- **After**: Direct random sampling with proper indexing

## Algorithm Flow:

1. **Flatten budgets**: `budgets_flat = budget.view(num_rows)`
2. **Calculate total elements**: `total_elements = sum(budgets)`
3. **Create ptr array**: Cumulative sum of budgets for sparse representation
4. **Generate random indices**: `idx_in_row` for each element to sample
5. **Create row mapping**: `row_id` using `repeat_interleave` to map each element to its row
6. **Calculate global indices**: `idx_global = idx_in_row + row_id * seq_len_keys`
7. **Calculate probabilities**: `data_global = sampling_probabilities[row_id]`
8. **Create mask**: Direct sparse construction

## Benefits:

1. **Memory Efficient**: Only allocates memory for actual sampled elements
2. **Computationally Efficient**: No dense tensor operations
3. **Cleaner Code**: More straightforward algorithm
4. **Better Performance**: Avoids unnecessary tensor operations and conversions

This approach is much more elegant and efficient than the previous vectorized approach!

---

**User**

Create a utility function for  this 
create_sampling_mask_with_per_head_budget( budgets: (b,h,q,1), sampling_probability (b.h,q,1)) in mask_attention_utilis.py and use it here

---

**Cursor**

I'll create the utility function in `mask_attention_utils.py` and then update the plan to use it.


Now I'll add the new utility function to the file:


```python
    return result


def _compute_masked_exp_attention_weights(

->

    return result


def create_sampling_mask_with_per_head_budget(
    budgets: torch.Tensor,
    sampling_probability: torch.Tensor,
    seq_len_keys: int,
    start_idx: int,
    end_idx: int,
    dtype: torch.dtype = torch.float32,
) -> Mask:
    """Create a sampling mask with per-head budget using direct sparse construction.
    
    This function efficiently creates a sparse sampling mask by directly constructing
    the sparse representation without creating intermediate dense tensors.
    
    Args:
        budgets: Budget tensor of shape (b, h, q, 1) indicating how many elements to sample per row
        sampling_probability: Sampling probability tensor of shape (b, h, q, 1) 
        seq_len_keys: Length of the key sequence dimension
        start_idx: Starting index for sampling range (inclusive)
        end_idx: Ending index for sampling range (exclusive)
        dtype: Data type for the mask
        
    Returns:
        Mask object with sparse sampling representation
        
    Note:
        - Uses direct sparse construction for memory efficiency
        - Generates random indices within [start_idx, end_idx) for each element
        - Creates proper ptr array for sparse representation
        - Assigns sampling probabilities as mask data values
    """
    batch_size, num_heads, seq_len_queries, _ = budgets.shape
    
    # Reshape budget to (num_rows,) for easier processing
    num_rows = batch_size * num_heads * seq_len_queries
    budgets_flat = budgets.view(num_rows)  # (num_rows,)
    
    # Calculate total number of elements to sample
    total_elements = budgets_flat.sum().item()
    
    # Create ptr array using cumulative sum of budgets
    ptr = torch.cat([
        torch.zeros(1, dtype=torch.long, device=budgets.device),
        torch.cumsum(budgets_flat, dim=0)
    ])  # (num_rows + 1,)
    
    # Generate random indices within sampling range for each element
    idx_in_row = torch.randint(
        low=start_idx,
        high=end_idx,
        size=(total_elements,),
        device=budgets.device,
        dtype=torch.long
    )  # (total_elements,)
    
    # Create row indices by repeating each row index according to its budget
    row_id = torch.repeat_interleave(torch.arange(num_rows, device=budgets.device), budgets_flat)  # (total_elements,)
    
    # Calculate global indices
    idx_global = idx_in_row + row_id * seq_len_keys  # (total_elements,)
    
    # Get sampling probabilities for each element
    sampling_prob_flat = sampling_probability.view(num_rows)  # (num_rows,)
    data_global = sampling_prob_flat[row_id]  # (total_elements,)
    
    # Create the sampling mask directly using sparse index construction
    sampling_mask = Mask.create_mask_from_indices(
        shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
        indices=idx_global,
        ptr=ptr,
        data=data_global,
        dtype=dtype
    )
    
    return sampling_mask


def _compute_masked_exp_attention_weights(
```

I need to fix the linter errors. The issue is with the `total_elements` being a float and the `size` parameter expecting an int:


```python
    # Calculate total number of elements to sample
    total_elements = budgets_flat.sum().item()
    
    # Create ptr array using cumulative sum of budgets
    ptr = torch.cat([
        torch.zeros(1, dtype=torch.long, device=budgets.device),
        torch.cumsum(budgets_flat, dim=0)
    ])  # (num_rows + 1,)
    
    # Generate random indices within sampling range for each element
    idx_in_row = torch.randint(
        low=start_idx,
        high=end_idx,
        size=(total_elements,),
        device=budgets.device,
        dtype=torch.long
    )  # (total_elements,)

->

    # Calculate total number of elements to sample
    total_elements = int(budgets_flat.sum().item())
    
    # Create ptr array using cumulative sum of budgets
    ptr = torch.cat([
        torch.zeros(1, dtype=torch.long, device=budgets.device),
        torch.cumsum(budgets_flat, dim=0)
    ])  # (num_rows + 1,)
    
    # Generate random indices within sampling range for each element
    idx_in_row = torch.randint(
        low=start_idx,
        high=end_idx,
        size=(total_elements,),
        device=budgets.device,
        dtype=torch.long
    )  # (total_elements,)
```

Now let me update the plan to use this new utility function:


```markdown
#### Step 8: Create Adaptive Sampling Mask (Direct Sparse Construction)
```python
# Reshape budget to (num_rows, 1) for easier processing
num_rows = batch_size * num_heads * seq_len_queries
budgets_flat = budget.view(num_rows)  # (num_rows,)

# Calculate total number of elements to sample
total_elements = budgets_flat.sum().item()

# Create ptr array using cumulative sum of budgets
ptr = torch.cat([
    torch.zeros(1, dtype=torch.long, device=keys.device),
    torch.cumsum(budgets_flat, dim=0)
])  # (num_rows + 1,)

# Generate random indices within sampling range for each element
idx_in_row = torch.randint(
    low=start_idx,
    high=end_idx,
    size=(total_elements,),
    device=keys.device,
    dtype=torch.long
)  # (total_elements,)

# Create row indices by repeating each row index according to its budget
row_id = torch.repeat_interleave(torch.arange(num_rows, device=keys.device), budgets_flat)  # (total_elements,)

# Calculate global indices
idx_global = idx_in_row + row_id * seq_len_keys  # (total_elements,)

# Calculate sampling probabilities for each element
sampling_probabilities = budgets_flat / sampling_range  # (num_rows,)
data_global = sampling_probabilities[row_id]  # (total_elements,)

# Create the adaptive mask directly using sparse index construction
adaptive_mask = Mask.create_mask_from_indices(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    indices=idx_global,
    ptr=ptr,
    data=data_global,
    dtype=previous_mask.dtype
)
```

->

#### Step 8: Create Adaptive Sampling Mask (Using Utility Function)
```python
# Calculate sampling probabilities
sampling_probabilities = budget / sampling_range  # (b, h, q, 1)

# Create adaptive sampling mask using utility function
from sparse_attention.utils.mask_attention_utils import create_sampling_mask_with_per_head_budget

adaptive_mask = create_sampling_mask_with_per_head_budget(
    budgets=budget,  # (b, h, q, 1)
    sampling_probability=sampling_probabilities,  # (b, h, q, 1)
    seq_len_keys=seq_len_keys,
    start_idx=start_idx,
    end_idx=end_idx,
    dtype=previous_mask.dtype
)
```
```

Perfect! I've successfully:

## 1. Created the Utility Function
Added `create_sampling_mask_with_per_head_budget()` to `mask_attention_utils.py` with:
- **Proper type annotations** for all parameters and return type
- **Comprehensive docstring** following Google style
- **Efficient implementation** using direct sparse construction
- **Fixed linter errors** by ensuring `total_elements` is an integer

## 2. Updated the Plan
Simplified Step 8 in the plan to use the new utility function:
- **Cleaner code**: Reduced from ~25 lines to ~8 lines
- **Better abstraction**: Encapsulates the complex sparse construction logic
- **Reusable**: Can be used by other maskers that need sampling masks

## Key Features of the Utility Function:

### **Parameters:**
- `budgets: (b, h, q, 1)` - Number of elements to sample per row
- `sampling_probability: (b, h, q, 1)` - Sampling probabilities per row
- `seq_len_keys: int` - Length of key sequence dimension
- `start_idx, end_idx: int` - Sampling range boundaries
- `dtype: torch.dtype` - Data type for the mask

### **Implementation:**
- **Memory efficient**: Only allocates memory for actual sampled elements
- **Direct sparse construction**: Uses `Mask.create_mask_from_indices()`
- **Proper indexing**: Handles global index calculation correctly
- **Vectorized operations**: Uses `torch.repeat_interleave` and `torch.randint`

### **Benefits:**
1. **Reusability**: Can be used by other sampling-based maskers
2. **Maintainability**: Centralized logic for sampling mask creation
3. **Performance**: Optimized sparse construction without dense intermediates
4. **Type safety**: Strong type annotations prevent runtime errors

The plan is now much cleaner and the utility function provides a reusable, efficient way to create sampling masks with per-head budgets!

---

**User**

Can you clean up the plan with shorter comments and new lines

---

**Cursor**

I'll clean up the plan with shorter comments and better formatting:


```markdown
# AdaptiveSamplingMasker Implementation Plan

## Overview
Adaptive sampling masker with statistical error bounds. Combines base sampling with adaptive budget allocation.

## Configuration
```python
@dataclass
class AdaptiveSamplingMaskerConfig(SamplingMaskerConfig):
    base_rate_sampling: Union[int, float]  # Base rate (0,1) if float
    epsilon: float  # Error bound (0,1)
    delta: float   # Confidence bound (0,1)
    init_offset: int  # Start index
    local_offset: int  # End offset
```

## Implementation

### Class Structure
```python
@MaskerRegistry.register(AdaptiveSamplingMaskerConfig)
class AdaptiveSamplingMasker(SamplingMasker):
    def __init__(self, config: AdaptiveSamplingMaskerConfig):
        super().__init__(config)
        self.base_rate_sampling = config.base_rate_sampling
        self.epsilon = config.epsilon
        self.delta = config.delta
        self.init_offset = config.init_offset
        self.local_offset = config.local_offset
        self.delta_ppf = norm.ppf(1 - self.delta)
```

### add_mask Method

#### Step 1: Early Exit
```python
if previous_mask.is_full_mask():
    return previous_mask
```

#### Step 2: Compute Attention Scores
```python
batch_size, num_heads, seq_len_queries, seq_len_keys = extract_dimensions(keys, queries)
raw_attention_scores = torch.matmul(queries, keys.transpose(-2, -1))
max_scores = torch.max(raw_attention_scores, dim=-1, keepdim=True)[0]
expwts = torch.exp(raw_attention_scores - max_scores)  # (b, h, q, k)
```

#### Step 3: Static Denominator
```python
from sparse_attention_hub.sparse_attention.utils.mask_attention_utils import apply_inv_mask_sum
static_denominator = apply_inv_mask_sum(expwts, previous_mask)  # (b, h, q, 1)
```

#### Step 4: Base Sampling + Std Estimation
```python
start_idx = self.init_offset
end_idx = seq_len_keys - self.local_offset
sampling_range = end_idx - start_idx

# Determine base samples
if isinstance(self.base_rate_sampling, int):
    num_base_samples = self.base_rate_sampling
else:
    num_base_samples = int(self.base_rate_sampling * sampling_range)

# Create base sampling indices
base_row_wise_idx = torch.randint(
    low=start_idx, high=end_idx,
    size=(batch_size, num_heads, seq_len_queries, num_base_samples),
    device=keys.device
)

# Extract sampled values
sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)

# Compute std estimate
total_rows = batch_size * num_heads * seq_len_queries
row_sampled_values = sampled_values.view(total_rows, num_base_samples)
std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)
std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)

# Create base mask
base_data = torch.full_like(base_row_wise_idx, self.base_rate_sampling, dtype=keys.dtype)
base_sampling_mask = Mask.create_from_row_wise_idx(
    shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),
    row_wise_idx=base_row_wise_idx,
    data=base_data,
    type="index",
    dtype=previous_mask.dtype
)
```

#### Step 5: Sampled Denominator
```python
sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)  # (b, h, q, 1)
```

#### Step 6: Total Denominator
```python
estimated_denominator = static_denominator + sampled_denominator  # (b, h, q, 1)
```

#### Step 7: Adaptive Budgets
```python
epsilon_allowable_error = self.epsilon * estimated_denominator
budget_numerator = self.delta_ppf * std_estimate * sampling_range
budget = torch.clamp(
    (budget_numerator / epsilon_allowable_error) ** 2,
    min=1, max=sampling_range
).long()  # (b, h, q, 1)
```

#### Step 8: Adaptive Mask
```python
sampling_probabilities = budget / sampling_range  # (b, h, q, 1)

from sparse_attention.utils.mask_attention_utils import create_sampling_mask_with_per_head_budget
adaptive_mask = create_sampling_mask_with_per_head_budget(
    budgets=budget,
    sampling_probability=sampling_probabilities,
    seq_len_keys=seq_len_keys,
    start_idx=start_idx,
    end_idx=end_idx,
    dtype=previous_mask.dtype
)
```

#### Step 9: Merge and Return
```python
combined_mask = base_sampling_mask.merge_mask(adaptive_mask, inplace=False)
return previous_mask.merge_mask(combined_mask, inplace=False)
```

## Key Points
- **Numerical stability**: Max trick for exponentials
- **Efficiency**: Pre-compute delta_ppf, use sparse operations
- **Statistical correctness**: Proper error bounds and budget computation
- **Error handling**: Validate config, handle edge cases

## File Structure
```
sparse_attention_hub/sparse_attention/research_attention/maskers/sampling/implementations/
├── adaptive_sampling.py
└── __init__.py
```

## Testing
- Unit tests: config validation, edge cases, statistical properties
- Integration tests: end-to-end functionality, performance
- Statistical tests: error bounds, confidence intervals
```

Perfect! I've cleaned up the plan with:

## Key Improvements:

### **Shorter Comments**
- Removed verbose explanations and kept only essential information
- Used concise, action-oriented comments
- Eliminated redundant explanations

### **Better Formatting**
- Reduced line spacing for better readability
- Grouped related concepts together
- Used consistent formatting throughout

### **Streamlined Content**
- **Overview**: Reduced from 3 paragraphs to 1 sentence
- **Configuration**: Removed validation rules (can be added in implementation)
- **Implementation**: Kept only essential code with minimal comments
- **Key Points**: Condensed from 4 detailed sections to 4 bullet points
- **Testing**: Simplified to 3 concise categories

### **Code Clarity**
- Removed excessive inline comments
- Kept only shape annotations where needed
- Simplified variable names and expressions
- Maintained logical flow without verbosity

The plan is now much more concise and easier to read while retaining all the essential implementation details. It's ready for implementation with clear, actionable steps!

