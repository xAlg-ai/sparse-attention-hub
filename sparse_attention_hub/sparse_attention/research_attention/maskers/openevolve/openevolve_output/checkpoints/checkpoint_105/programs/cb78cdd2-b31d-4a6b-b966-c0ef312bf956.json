{"id": "cb78cdd2-b31d-4a6b-b966-c0ef312bf956", "code": "\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # Shrink factor that trades accuracy for sparsity (0.7-0.8 is typical)\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 3 samples since it is used for std estimation\n        # (two samples often yield zero variance and unstable budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: top-k high-mass coverage plus aggressive adaptive budget for optimal sparsity and quality.\n\n        - First, select the minimum number of tokens per row (query) that account for at least 98% of exp(atten) mass.\n        - Then, for any long-tail, sample adaptively with an aggressive statistical error budget.\n        - This minimizes density while preserving near-full attention approximation.\n\n        The mask is the union of: (a) high-mass top-k mask, (b) adaptive random mask, (c) any previous mask.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Dynamic parameterization based on sequence length for best density/error tradeoff\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.12\n            self.delta = 0.10\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.010\n            self.epsilon = 0.15\n            self.delta = 0.12\n        else:\n            self.base_rate_sampling = 0.008\n            self.epsilon = 0.17\n            self.delta = 0.13\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --------------- (1) Top-mass coverage ---------------\n        # Find minimum k s.t. cumsum(expwts) covers \u226598% of row mass for best density/error (empirically best).\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.98).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for sparsity, but never less than 1\n        max_topk = min(10, seq_len_keys // 10 + 2)\n        k1 = torch.clamp(k1, min=1, max=max_topk)\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail: aggressively sparsified for very low-variance rows\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        min_budget = num_base_samples\n        # For maximum sparsity: shrink for very low-variance rows\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink = torch.where(rel_std < 0.10, 0.10, 0.34)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget)\n        # Cap absolute budget, never less than min_budget\n        max_budget = max(min_budget, int(0.04 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # For ultra-flat rows, skip tail sampling (use only top-mass)\n        flat_row = (rel_std < 0.025).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n", "language": "python", "parent_id": "eed91897-57e6-4328-ab79-11ddb074bb6b", "generation": 5, "timestamp": 1757496247.5327, "iteration_found": 93, "metrics": {"density": 100, "error": 100, "combined_score": -100}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 9 lines with 18 lines\nChange 2: Replace 93 lines with 92 lines", "parent_metrics": {"density": 100, "error": 100, "combined_score": -100}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert statistician and python / PyTorch programmer specializing statistical analysis \nof approximations. Focus on improving specified algorihm's ability to select the least amount of tokens (entries in the Mask which are non-zero) while maintaining the approximation quality. \nYou have to write the add_mask function using native pytorch operations -- mask created in this function should be as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nThis file is part of a project which is a comprehensive framework designed for implementing and experimenting with various sparse attention mechanisms in deep learning models.  You will be improving on one of the Maskers. \nOverview of Maskers:\nMaskers are the core components that define how attention patterns are computed in the sparse attention framework. They implement different strategies for determining which key-query pairs should be attended to. A sparse attention in this framework is a series of Masker. Each Masker adds tokens that need to be activated in sparse attention. The data structure to store these active tokens is a Mask class. Details of the Mask class are as follows\n### **Mask Class Structure and Functions**\nThe `Mask` class is a sophisticated data structure that represents attention patterns in multiple formats for optimal performance and memory usage. It is a sparse matrix of size `(batch_size, heads, q_len, k_len)` where if an element is 0, that token is inactive for the particular head and query. If it is non-zero, then it is active and the value stores the probability with which the token is sampled. \n#### **Core Attributes:**\n```python\nclass Mask:\n    def __init__(self, shape, dtype, mask=None, indices=None, ptr=None, \n                data=None, from_dense_mask=False, from_index=False, is_full=False):\n        self.shape = shape                    # Shape of the mask (*, n)\n        self.dtype = dtype                    # Data type for mask values\n        self.from_dense_mask = from_dense_mask  # Whether created from dense tensor\n        self.from_index = from_index          # Whether created from sparse indices\n        self.is_full = is_full                # Whether this is a full mask (all 1.0)\n        \n        # Storage attributes (only one is active at a time)\n        self.mask = None      # Dense tensor representation\n        self.indices = None   # Sparse indices\n        self.ptr = None       # Sparse pointer array\n        self.data = None      # Sparse data values\n```\n#### **Mask Class Functions and Signatures:**\n**Creation Methods:**\n```python\n@classmethod\ndef create_full_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a full mask (all elements are 1.0) with optimized representation\n@classmethod\ndef create_mask_from_dense_mask(shape: Tuple[int, ...], mask: torch.Tensor, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from dense mask tensor\n@classmethod\ndef create_mask_from_indices(shape: Tuple[int, ...], indices: torch.Tensor, ptr: torch.Tensor, data: Optional[torch.Tensor] = None, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from sparse indices and pointer representation\n@classmethod\ndef create_from_row_wise_idx(shape: Tuple[int, ...], row_wise_idx: torch.Tensor, data: torch.Tensor, type: str = \"index\", dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from row-wise indices\n@classmethod\ndef create_empty_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32, mask_type: str = \"dense\") -> \"Mask\"\n# Creates a mask object with all values set to zero\n```\n**Access Methods:**\n```python\ndef get_dense_mask(self) -> torch.Tensor\n# Returns the dense mask representation\ndef get_index_mask(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n# Returns the sparse index representation (indices, ptr, data)\ndef apply_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the mask to an input tensor (0 => inactive, >0 => active with weight)\ndef apply_inv_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the inverse mask to an input tensor (output[IDX] = input[IDX] * 1.0 / mask[IDX])\n```\n**Utility Methods:**\n```python\ndef is_full_mask(self) -> bool\n# Checks if this is a full mask (all elements are 1.0)\ndef is_empty(self) -> bool\n# Checks if the mask is empty (all elements are 0.0)\ndef get_density(self) -> float\n# Returns the density/sparsity of the mask (ratio of non-zero elements)\ndef merge_mask(self, other_mask: \"Mask\", inplace: bool = False) -> \"Mask\"\n# Merges this mask with another mask in sparse format\n```\n**Three Representation Formats:**\n1. **Dense Representation** (`from_dense_mask=True`): Full tensor storage for compatibility\n2. **Sparse Representation** (`from_index=True`): CSR-like format for memory efficiency  \n3. **Full Mask Optimization** (`is_full=True`): Zero storage for all-ones masks\nMask is a sparse matrix of size batch_size, heads, q_len, k_len . where if an element is 0, that token is inactive for the particular head and query. if it is non-zero then it is active. The final attention using mask is computed as follows,\n### **`get_masked_attention_output` Function:**\n**Function Signature:**\n```python\ndef get_masked_attention_output(\n    module: nn.Module,\n    queries: torch.Tensor,\n    keys: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: Optional[torch.Tensor],\n    scaling: float,\n    dropout: float,\n    sparse_attention_mask: Mask,\n    return_attention_weights: bool = False,\n    **kwargs: Dict[str, Any],\n) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n```\n**English Description:**\nThis function computes masked attention output by dividing numerator by denominator. It takes the attention module, query/key/value tensors, optional attention mask, scaling factor, dropout probability, and the sparse attention mask object. It optionally returns attention weights along with the output. The function efficiently computes exponential attention weights once and reuses them for both numerator and denominator calculations to avoid redundant computation. **Important**: The function uses `apply_inv_mask` (inverse mask application) during the computation process, which applies the inverse of the mask weights to the attention scores.\n**Key Steps:**\n1. **Compute exponential attention weights** using `_compute_masked_exp_attention_weights`\n2. **Apply inverse mask** using `sparse_attention_mask.apply_inv_mask()` to the exponential attention weights\n3. **Calculate numerator** by multiplying exponential weights with values\n4. **Calculate denominator** by summing exponential weights along the last dimension\n5. **Compute final output** by dividing numerator by denominator\n6. **Optionally return attention weights** by normalizing exponential weights with denominator\n**Return Values:**\n- If `return_attention_weights=False`: Returns attention output tensor of shape `(b, h, sq, d)`\n- If `return_attention_weights=True`: Returns tuple of `(attention_output, attention_weights)` where attention_weights has shape `(b, h, sq, sk)`\nYou are supposed to write add_mask function for this class which decides what tokens are active and what weights are associated with them . The `add_mask` function is the core method in every masker that defines how attention patterns are computed and applied. It serves as the primary interface between the attention mechanism and the masking logic.\n### **Function Signature:**\n```python\ndef add_mask(\n    self,\n    keys: torch.Tensor,\n    queries: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: torch.Tensor,\n    scaling: float,\n    dropout: float,\n    sparse_meta_data: Dict[Any, Any],\n    previous_mask: Mask,\n    **kwargs: Dict[str, Any],\n) -> Mask:\n```\n### **Key Responsibilities:**\n1. **Pattern Computation**: Determines which key-query pairs should be attended to based on the masker's strategy\n2. **Mask Generation**: Creates a `Mask` object representing the computed attention pattern\n3. **Mask Merging**: Combines the new mask with any previous masks to build cumulative attention patterns\nImportant things to remember: Use query and key head computation to compute num_groups and use that to repeat keys before you use them. \n\nFocus on evolving the add_mask function to produce the best makser possible that is as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nExplain step-by-step the reasoning process for your solution and how this will lead to a better masker.\n", "user": "# Current Program Information\n- Current performance metrics: - density: 100.0000\n- error: 100.0000\n- combined_score: -100.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: density, error. Consider continuing with similar changes.\n- Metrics showing regression: combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: density: -0.0709, error: -0.0356, combined_score: -0.0533\n- Outcome: Regression in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: density: -0.0711, error: -0.0352, combined_score: -0.0532\n- Outcome: Regression in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: density: -0.0706, error: -0.0357, combined_score: -0.0532\n- Outcome: Regression in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: -0.0532)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Add an adaptive sparse attention mask by aggressively shrinking budget while \n        retaining statistical guarantees, simplifying the code for maintainability.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Adaptive parameters based on sequence length (keeps error low on long sequences)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        # Keep a very small global/local offset to avoid extreme positions\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Precompute delta PPF once\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights (after masking)\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Sampling budget setup ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Statistical error-controlled budget (pre-sparsification)\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # Aggressive sparsification with empirically-validated heuristics\n        # ------------------------------------------------------------------ #\n        # (1) Shrink budget with a strong scaling factor\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # (2) Maintain a robust minimum number of samples\n        min_base = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) Hard upper cap: no more than 8% of keys\n        max_budget = max(min_base, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Keep at least 2 samples for very short sequences\n        budget = torch.clamp(budget, min=2)\n\n        # (5) Extra sparsity for queries that already have a very large static mass\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(budget, max=max(min_base, int(0.05 * sampling_range)))\n\n        # ------------------------------------------------------------------ #\n        # \u2776  Deterministic TOP-MASS: keep the minimum k tokens that cover \u226597 %\n        # ------------------------------------------------------------------ #\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = cumsum[..., -1:]\n        k_97 = (cumsum / (total_mass + 1e-8) < 0.97).sum(dim=-1, keepdim=True) + 1\n        k_97 = torch.clamp(k_97, min=1, max=min(12, seq_len_keys // 8 + 1))\n\n        max_topk = int(k_97.max().item())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        top_mask = arange_topk < k_97                       # shape (b,h,q,max_topk)\n        top_idx = sorted_idx[..., :max_topk]                # same shape as top_mask\n\n        top_data = torch.where(\n            top_mask,\n            torch.ones_like(top_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(top_idx, dtype=previous_mask.dtype),\n        )\n\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # \u2777  MUCH SMALLER STATISTICAL TAIL after accounting for top-mass\n        # ------------------------------------------------------------------ #\n        relative_mass = (cumsum[..., -1:] / (static_denominator + 1e-8)).clamp(max=1.0)\n        tail_scale = torch.where(relative_mass > 0.97, 0.25, 0.45)  # aggressive shrink\n        budget = torch.ceil(budget.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n\n        # If almost every key already selected deterministically, skip tail\n        budget = torch.where(k_97 >= seq_len_keys - 2, torch.zeros_like(budget), budget)\n\n        # ------------------------------------------------------------------ #\n        # \u2778  Build probabilistic TAIL mask and merge everything\n        # ------------------------------------------------------------------ #\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous  \u222a  deterministic-top  \u222a  statistical-tail\n        merged_mask = (\n            previous_mask.merge_mask(topmass_mask, inplace=False)\n            .merge_mask(adaptive_mask, inplace=False)\n        )\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0706), Performs well on error (-0.0357), Performs well on combined_score (-0.0532)\n\n\n### Program 2 (Score: -0.0532)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Improved hybrid: deterministically select minimal set of top keys per query to cover \u226597% exp(attn) mass,\n        and sample adaptively and aggressively only the remaining low-mass tail. This produces much sparser masks while preserving approximation.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # More adaptive, dynamic parameters (based on top-performing versions, improved for quality/density tradeoff)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02\n            self.epsilon = 0.2\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018\n            self.epsilon = 0.22\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # -- Hybrid: select minimal number of keys covering \u226597% mass per row, rest gets aggressive tail sampling --\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        frac = cumsum / (total + 1e-8)\n        # How many keys needed to reach \u226597% mass\n        k_97 = (frac < 0.97).sum(dim=-1, keepdim=True) + 1\n        k_97 = torch.clamp(k_97, min=1, max=min(10, seq_len_keys // 10 + 1))\n        max_topk = int(k_97.max())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = arange_topk < k_97\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # Get main sampling parameters for the tail\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation (used for adaptive tail only)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(base_row_wise_idx, num_base_samples / sampling_range, dtype=previous_mask.dtype)\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Aggressively shrink tail budget where possible (if most mass is covered)\n        rel_mass_covered = cumsum[..., -1:] / (static_denominator + 1e-8)\n        tail_scale = torch.where(rel_mass_covered > 0.97, 0.19, 0.38)\n        min_base = max(num_base_samples, 2)\n        budget = torch.ceil(budget_squared.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Remove tail for ultra-short cases where top mass covers almost all tokens\n        budget = torch.where(k_97 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous \u222a topmass \u222a adaptive tail\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0711), Performs well on error (-0.0352), Performs well on combined_score (-0.0532)\n\n\n### Program 3 (Score: -0.0533)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # --------- Improved: Hybrid top-mass + aggressively shrunk adaptive tail --------- #\n\n        # (1) Deterministic: minimal top-k per row to cover \u226598% of exp(attn) mass\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        frac = cumsum / (total + 1e-8)\n        k_98 = (frac < 0.98).sum(dim=-1, keepdim=True) + 1\n        # More aggressive max cap for density (up to 12 or seq_len_keys//7+1)\n        k_98 = torch.clamp(k_98, min=1, max=min(12, seq_len_keys // 7 + 1))\n        max_topk = int(k_98.max())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = arange_topk < k_98\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype))\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # (2) Aggressive statistical tail: shrink budget more if almost all mass is covered\n        rel_mass_covered = cumsum[..., -1:] / (static_denominator + 1e-8)\n        # Lower tail scale when top mass covers almost everything\n        tail_scale = torch.where(rel_mass_covered > 0.98, 0.12, 0.27)\n        min_base = max(num_base_samples, 2)\n        budget = torch.ceil(budget.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.035 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Remove tail when top-mass covers almost all keys\n        budget = torch.where(k_98 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Final mask: previous \u222a topmass \u222a aggressive adaptive tail\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0709), Performs well on error (-0.0356), Performs well on combined_score (-0.0533)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -0.0533)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: deterministically select minimal set of top keys per query to cover \u226597% exp(attn) mass,\n        and sample adaptively and aggressively only the remaining low-mass tail. This produces much sparser masks while preserving approximation.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # More adaptive, dynamic parameters (based on top-performing versions, improved for quality/density tradeoff)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02\n            self.epsilon = 0.2\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018\n            self.epsilon = 0.22\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # -- Hybrid: select minimal number of keys covering \u226597% mass per row, rest gets aggressive tail sampling --\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        frac = cumsum / (total + 1e-8)\n        # How many keys needed to reach \u226597% mass\n        k_97 = (frac < 0.97).sum(dim=-1, keepdim=True) + 1\n        k_97 = torch.clamp(k_97, min=1, max=min(10, seq_len_keys // 10 + 1))\n        max_topk = int(k_97.max())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = arange_topk < k_97\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # Get main sampling parameters for the tail\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation (used for adaptive tail only)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(base_row_wise_idx, num_base_samples / sampling_range, dtype=previous_mask.dtype)\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Aggressively shrink tail budget where possible (if most mass is covered)\n        rel_mass_covered = cumsum[..., -1:] / (static_denominator + 1e-8)\n        tail_scale = torch.where(rel_mass_covered > 0.97, 0.19, 0.38)\n        min_base = max(num_base_samples, 2)\n        budget = torch.ceil(budget_squared.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Remove tail for ultra-short cases where top mass covers almost all tokens\n        budget = torch.where(k_97 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous \u222a topmass \u222a adaptive tail\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n\n### Program D2 (Score: -0.0534)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Improved hybrid: select the minimal number of top keys per query to cover \u226597% exp(attn) mass\n        and adaptively, aggressively sample the tail. This yields much sparser masks with high approximation quality.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Adaptive, dynamic parameters based on sequence length (empirically best from leaderboard)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02\n            self.epsilon = 0.2\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018\n            self.epsilon = 0.22\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Top-mass: minimal set covering \u226597% exp(attn) mass ---\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        frac = cumsum / (total + 1e-8)\n        # How many keys needed to reach \u226597% mass (variable per row)\n        k_97 = (frac < 0.97).sum(dim=-1, keepdim=True) + 1\n        k_97 = torch.clamp(k_97, min=1, max=min(10, seq_len_keys // 10 + 1))\n        max_topk = int(k_97.max())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = arange_topk < k_97\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --- Tail: adaptively and aggressively sample the remaining keys ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling for std estimation\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(base_row_wise_idx, num_base_samples / sampling_range, dtype=previous_mask.dtype)\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Aggressively shrink tail budget if most mass already covered\n        rel_mass_covered = cumsum[..., -1:] / (static_denominator + 1e-8)\n        tail_scale = torch.where(rel_mass_covered > 0.97, 0.19, 0.38)\n        min_base = max(num_base_samples, 2)\n        budget = torch.ceil(budget_squared.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Remove tail for queries where topmass covers nearly all tokens\n        budget = torch.where(k_97 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous \u222a topmass \u222a adaptive tail\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: -0.0532, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Add an adaptive sparse attention mask by aggressively shrinking budget while \n        retaining statistical guarantees, simplifying the code for maintainability.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Adaptive parameters based on sequence length (keeps error low on long sequences)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        # Keep a very small global/local offset to avoid extreme positions\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Precompute delta PPF once\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights (after masking)\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Sampling budget setup ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Statistical error-controlled budget (pre-sparsification)\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # Aggressive sparsification with empirically-validated heuristics\n        # ------------------------------------------------------------------ #\n        # (1) Shrink budget with a strong scaling factor\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # (2) Maintain a robust minimum number of samples\n        min_base = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) Hard upper cap: no more than 8% of keys\n        max_budget = max(min_base, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Keep at least 2 samples for very short sequences\n        budget = torch.clamp(budget, min=2)\n\n        # (5) Extra sparsity for queries that already have a very large static mass\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(budget, max=max(min_base, int(0.05 * sampling_range)))\n\n        # ------------------------------------------------------------------ #\n        # \u2776  Deterministic TOP-MASS: keep the minimum k tokens that cover \u226597 %\n        # ------------------------------------------------------------------ #\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = cumsum[..., -1:]\n        k_97 = (cumsum / (total_mass + 1e-8) < 0.97).sum(dim=-1, keepdim=True) + 1\n        k_97 = torch.clamp(k_97, min=1, max=min(12, seq_len_keys // 8 + 1))\n\n        max_topk = int(k_97.max().item())\n        arange_topk = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        top_mask = arange_topk < k_97                       # shape (b,h,q,max_topk)\n        top_idx = sorted_idx[..., :max_topk]                # same shape as top_mask\n\n        top_data = torch.where(\n            top_mask,\n            torch.ones_like(top_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(top_idx, dtype=previous_mask.dtype),\n        )\n\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # \u2777  MUCH SMALLER STATISTICAL TAIL after accounting for top-mass\n        # ------------------------------------------------------------------ #\n        relative_mass = (cumsum[..., -1:] / (static_denominator + 1e-8)).clamp(max=1.0)\n        tail_scale = torch.where(relative_mass > 0.97, 0.25, 0.45)  # aggressive shrink\n        budget = torch.ceil(budget.float() * tail_scale).long()\n        budget = torch.clamp(budget, min=min_base)\n\n        # If almost every key already selected deterministically, skip tail\n        budget = torch.where(k_97 >= seq_len_keys - 2, torch.zeros_like(budget), budget)\n\n        # ------------------------------------------------------------------ #\n        # \u2778  Build probabilistic TAIL mask and merge everything\n        # ------------------------------------------------------------------ #\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous  \u222a  deterministic-top  \u222a  statistical-tail\n        merged_mask = (\n            previous_mask.merge_mask(topmass_mask, inplace=False)\n            .merge_mask(adaptive_mask, inplace=False)\n        )\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 18 lines with 63 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 2 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n\n        # --- DENSITY-BOOSTING STRATEGY ---\n        # Make budget scaling adaptive based on error feedback if available, or use more aggressive static scaling.\n        # Aim: Reduce density without hurting error.\n\n        # (1) Scale budget more aggressively (tuned lower empirically).\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # (2) Use slightly higher minimum base (helps std and very sparse zones)\n        min_base = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) Tighter cap: at most 5% of available keys per row (was 6%)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Enforce a sensible minimum (2 for very short sequence regions)\n        budget = torch.clamp(budget, min=2)\n\n        # (5) If static_denominator is very large, lower sampling even more for ultra-sparse attention\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(budget, max=max(min_base, int(0.03 * sampling_range)))\n\n        # (6) Prune budget to zero for very low estimated_denominator (ultra-sparse)\n        # Reduce budget where estimated_denominator < 0.02 * static_denominator.max()\n        if estimated_denominator is not None:\n            min_mask_threshold = 0.02 * static_denominator.max()\n            mask_sparse_rows = (estimated_denominator < min_mask_threshold)\n            if torch.any(mask_sparse_rows):\n                budget = budget.masked_fill(mask_sparse_rows, 0)\n\n        # (7) Sampling probabilities re-computed after tightening caps\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Make mask even sparser if most weights are concentrated (top-k style)\n        if expwts.numel() > 0:\n            # Estimate for each query: how much of total expwts mass is in top tokens?\n            topk = min(4, sampling_range)\n            sorted_expwts, _ = torch.sort(expwts[..., start_idx:end_idx], dim=-1, descending=True)\n            expwts_sum = expwts[..., start_idx:end_idx].sum(dim=-1, keepdim=True) + 1e-8\n            frac_top = sorted_expwts[..., :topk].sum(dim=-1, keepdim=True) / expwts_sum\n            # If most rows have top-4 covering >60% of the mass, we can make budget even smaller\n            ultra_sparse_condition = (frac_top > 0.6).squeeze(-1)\n            if torch.any(ultra_sparse_condition):\n                budget = torch.where(ultra_sparse_condition, torch.clamp(budget, max=min_base+1), budget)\n            # Recompute probabilities\n            sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Create adaptive mask and merge with previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 21 lines with 21 lines\nChange 2: Replace 12 lines with 25 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 3 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        # Use a hybrid deterministic+adaptive approach for maximum sparsity and quality.\n\n        # --- (A) Deterministic top-mass mask to guarantee main expwts mass is covered ---\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        # Find the minimum k that covers at least 98% of total exp(attn) mass\n        k_98 = (cumsum / (total + 1e-8) < 0.98).sum(dim=-1, keepdim=True) + 1\n        # Clamp range: at least 2, at most 12 (or 6% of keys if shorter)\n        k_98 = torch.clamp(k_98, min=2, max=min(12, seq_len_keys // 16 if seq_len_keys >= 32 else seq_len_keys))\n        max_topk = int(k_98.max())\n        rows = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = rows < k_98\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --- (B) Aggressive, even sparser random sampling for the tail (everything not top-mass) ---\n        scale = 0.43  # much more aggressive scaling for the tail\n        budget = torch.ceil(budget.float() * scale).long()\n        # Still require a few tail samples for std, but allow ultra-low min\n        min_base = max(num_base_samples, 2)\n        budget = torch.clamp(budget, min=min_base)\n        # For rows where almost all keys are in the topmass, set tail budget to zero\n        budget = torch.where(k_98 >= seq_len_keys - 2, torch.zeros_like(budget), budget)\n        # Cap: at most 5% of available keys per query, but not less than min_base\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Clamp for very short rows\n        budget = torch.clamp(budget, min=2)\n\n        # If the row's static_denominator is already high, let it be even sparser in the tail\n        high_static = static_denominator > torch.quantile(static_denominator, 0.8)\n        if high_static.any():\n            budget = torch.where(high_static, torch.clamp(budget, max=max(min_base, int(0.03 * sampling_range))), budget)\n\n        # Compute per-row sampling probabilities\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Make sure numerical stability\n        sampling_probabilities = torch.clamp(sampling_probabilities, min=0.0, max=1.0)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge: previous \u222a top-mass \u222a tail\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 34 lines with 62 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 4 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # Shrink factor that trades accuracy for sparsity (0.7-0.8 is typical)\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        # ------------------------------------------------------------------ #\n        #  \u2728  REWRITTEN SPARSIFICATION LOGIC (leader-board proven)          #\n        # ------------------------------------------------------------------ #\n        # We drop the former \u201ctop-mass + tail\u201d strategy that turned out to\n        # activate far too many tokens (100 % density!) and replace it with\n        # the compact adaptive sampler that obtained the best density/error\n        # numbers in earlier submissions.\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # ---------- dynamic hyper-parameters wrt sequence length ---------- #\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10_000:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.02, 0.20, 0.20\n        elif seq_len_keys > 5_000:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.018, 0.22, 0.22\n        else:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.015, 0.25, 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If the existing mask is already dense we do nothing.\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # ---------- shapes & stable exp-attention  ---------- #\n        dims = self._extract_tensor_dimensions(keys, queries)\n        b, h, sq, sk = dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        expwts = self._compute_exp_attention_scores(queries, keys, scaling, attention_mask)\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # ---------- base sampling for variance estimate ---------- #\n        start, end, span = self._get_sampling_range(sk)\n        n_base = self._get_base_sample_count(span)\n        base_mask, std_est = self._get_std_estimate_using_base_sample(\n            expwts, b, h, sq, sk, start, end, n_base, previous_mask.dtype\n        )\n        samp_den = apply_inv_mask_sum(expwts, base_mask)\n        est_den  = static_denominator + samp_den\n\n        # ---------- statistical budget & sparsity boosts ---------- #\n        budget = self._compute_adaptive_budget(std_est, est_den, span)\n        budget = torch.ceil(budget.float() * 0.54).long()          # global shrink\n        min_b  = max(n_base, 4)\n        max_b  = max(min_b, int(0.08 * span))\n        budget = torch.clamp(budget, min=min_b, max=max_b)\n        if torch.median(static_denominator) > 5.0:                 # extra reduction\n            budget = torch.clamp(budget, max=max(min_b, int(0.06 * span)))\n        budget = torch.clamp(budget, min=2)\n\n        # ---------- build sparse mask ---------- #\n        probs = (budget / span).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget, sampling_probability=probs,\n            seq_len_keys=sk, start_idx=start, end_idx=end, dtype=previous_mask.dtype\n        )\n\n        # ---------- merge & early-return ---------- #\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # NOTE: the legacy \u201ctop-mass + tail\u201d implementation that follows\n        # is now unreachable but retained for reference.\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 3 samples since it is used for std estimation\n        # (two samples often yield zero variance and unstable budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        DENSITY-BOOSTING: Compact adaptive mask with minimal density & statistical guarantees.\n        - No top-mass deterministic selection, only statistically adaptive random sampling.\n        - Budget is shrunk aggressively based on variance feedback for each row.\n        - All logic pure PyTorch and preserves numerical/statistical safety.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Strongly aggressive static for all seq lens\n        self.base_rate_sampling = 0.008  # keep base sampling small for variance, not coverage\n        self.epsilon = 0.15  # tigher error margin\n        self.delta = 0.13\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        min_budget = num_base_samples\n        max_budget = max(min_budget, int(0.033 * sampling_range))\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        # More aggressive shrink for low-variance rows\n        shrink = torch.where(rel_std < 0.11, 0.22, 0.37)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # If nearly flat row, minimal samples only\n        flat_row = (rel_std < 0.04).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n            sampling_probabilities = torch.where(\n                flat_row, torch.full_like(sampling_probabilities, min_budget/sampling_range), sampling_probabilities\n            )\n\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 144 lines with 99 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 5 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: For each query/head row, include the minimum set of top-k tokens that cover 98% of the attention mass (\"top-mass\"),\n        then add a (shrunk) statistical tail for robustness, aggressively shrinking budget elsewhere.\n        This yields much higher sparsity without sacrificing approximation, especially for highly peaked attention.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        seq_len_keys = keys.shape[-2]\n        # Aggressive parameters for hybrid strategy; pushes for sparser mask\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.011\n            self.epsilon = 0.14\n            self.delta = 0.12\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.15\n            self.delta = 0.13\n        else:\n            self.base_rate_sampling = 0.013\n            self.epsilon = 0.16\n            self.delta = 0.14\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n        # (1) Top-mass: minimal tokens to cover ~98% attention mass per row\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k_mass = (mass_frac < 0.98).sum(dim=-1, keepdim=True) + 1\n        max_topk = min(14, seq_len_keys // 8)\n        k_mass = torch.clamp(k_mass, min=2, max=max_topk)\n        max_k = int(k_mass.max())\n        # Variable per-row top-k\n        row_indices = torch.arange(max_k, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k_mass)\n        expanded_sorted_idx = sorted_idx[..., :max_k]\n        k1_selected_idx = torch.where(k1_mask, expanded_sorted_idx, torch.zeros_like(expanded_sorted_idx))\n        k1_data = torch.where(k1_mask, torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype), torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype))\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # (2) Statistically adaptive random tail\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True).clamp(min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        # Shrink: much smaller tail where possible\n        shrink = torch.where(rel_std < 0.15, 0.20, 0.46)\n        min_budget = num_base_samples\n        max_budget = max(num_base_samples, int(0.05 * sampling_range))\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Ultra-flat rows: reduce tail even further\n        ultra_flat = (rel_std < 0.06).squeeze(-1)\n        if torch.any(ultra_flat):\n            budget = torch.where(ultra_flat, torch.full_like(budget, min_budget), budget)\n            sampling_probabilities = torch.where(ultra_flat, torch.full_like(sampling_probabilities, min_budget/sampling_range), sampling_probabilities)\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 117 lines with 123 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n\n# Current Program\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # Shrink factor that trades accuracy for sparsity (0.7-0.8 is typical)\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 3 samples since it is used for std estimation\n        # (two samples often yield zero variance and unstable budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: top-k high-mass coverage plus aggressive adaptive budget for optimal sparsity and quality.\n\n        - First, select the minimum number of tokens per row (query) that account for at least 98% of exp(atten) mass.\n        - Then, for any long-tail, sample adaptively with an aggressive statistical error budget.\n        - This minimizes density while preserving near-full attention approximation.\n\n        The mask is the union of: (a) high-mass top-k mask, (b) adaptive random mask, (c) any previous mask.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # More aggressive static for all seq lens, keeping parameterization stable\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.18\n        self.delta = 0.14\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --------------- (1) Top-mass coverage ---------------\n        # For each (b, h, q), find minimum k s.t. cumsum(expwts) covers \u226597% of row mass (empirically best tradeoff).\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.97).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for extreme cases for sparsity, but always allow at least 1 (rare very short sequence corner case)\n        max_topk = min(11, seq_len_keys // 9 + 2)\n        k1 = torch.clamp(k1, min=1, max=max_topk)\n\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail sampling as before, but be even more sparse for very low-variance rows\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        min_budget = num_base_samples\n        # For additional sparsity: lower shrink in more places, but always \u2265 min_budget\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink = torch.where(rel_std < 0.10, 0.16, 0.43)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget)\n        # Cap absolute budget more harshly, but never less than min_budget\n        max_budget = max(min_budget, int(0.045 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # For ultra-low variance rows (flat rows), skip tail sampling altogether (use only top-mass)\n        flat_row = (rel_std < 0.032).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["<<<<<<< SEARCH\n        seq_len_keys = keys.shape[-2]\n        # More aggressive static for all seq lens, keeping parameterization stable\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.18\n        self.delta = 0.14\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n=======\n        seq_len_keys = keys.shape[-2]\n        # Dynamic parameterization based on sequence length for best density/error tradeoff\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.12\n            self.delta = 0.10\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.010\n            self.epsilon = 0.15\n            self.delta = 0.12\n        else:\n            self.base_rate_sampling = 0.008\n            self.epsilon = 0.17\n            self.delta = 0.13\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n        # --------------- (1) Top-mass coverage ---------------\n        # For each (b, h, q), find minimum k s.t. cumsum(expwts) covers \u226597% of row mass (empirically best tradeoff).\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.97).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for extreme cases for sparsity, but always allow at least 1 (rare very short sequence corner case)\n        max_topk = min(11, seq_len_keys // 9 + 2)\n        k1 = torch.clamp(k1, min=1, max=max_topk)\n\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail sampling as before, but be even more sparse for very low-variance rows\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        min_budget = num_base_samples\n        # For additional sparsity: lower shrink in more places, but always \u2265 min_budget\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink = torch.where(rel_std < 0.10, 0.16, 0.43)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget)\n        # Cap absolute budget more harshly, but never less than min_budget\n        max_budget = max(min_budget, int(0.045 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # For ultra-low variance rows (flat rows), skip tail sampling altogether (use only top-mass)\n        flat_row = (rel_std < 0.032).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n=======\n        # --------------- (1) Top-mass coverage ---------------\n        # Find minimum k s.t. cumsum(expwts) covers \u226598% of row mass for best density/error (empirically best).\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.98).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for sparsity, but never less than 1\n        max_topk = min(10, seq_len_keys // 10 + 2)\n        k1 = torch.clamp(k1, min=1, max=max_topk)\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail: aggressively sparsified for very low-variance rows\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        min_budget = num_base_samples\n        # For maximum sparsity: shrink for very low-variance rows\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink = torch.where(rel_std < 0.10, 0.10, 0.34)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget)\n        # Cap absolute budget, never less than min_budget\n        max_budget = max(min_budget, int(0.04 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # For ultra-flat rows, skip tail sampling (use only top-mass)\n        flat_row = (rel_std < 0.025).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n>>>>>>> REPLACE"]}}}