{"id": "f3b3c37c-ef7d-438f-83f7-2d47ef03f3c5", "code": "\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n\n        # --- DENSITY-BOOSTING STRATEGY ---\n        # Make budget scaling adaptive based on error feedback if available, or use more aggressive static scaling.\n        # Aim: Reduce density without hurting error.\n\n        # (1) Scale budget more aggressively (tuned lower empirically).\n        budget = torch.ceil(budget.float() * 0.60).long()\n\n        # (2) Use slightly higher minimum base (helps std and very sparse zones)\n        min_base = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) Tighter cap: at most 5% of available keys per row (was 6%)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Enforce a sensible minimum (2 for very short sequence regions)\n        budget = torch.clamp(budget, min=2)\n\n        # (5) If static_denominator is very large, lower sampling even more for ultra-sparse attention\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(budget, max=max(min_base, int(0.03 * sampling_range)))\n\n        # (6) Prune budget to zero for very low estimated_denominator (ultra-sparse)\n        # Reduce budget where estimated_denominator < 0.02 * static_denominator.max()\n        if estimated_denominator is not None:\n            # Keep a minimal budget for rows with tiny denominator instead of dropping them completely\n            min_mask_threshold = 0.02 * static_denominator.max()\n            mask_sparse_rows = (estimated_denominator < min_mask_threshold)\n            if torch.any(mask_sparse_rows):\n                budget = torch.where(mask_sparse_rows, torch.full_like(budget, min_base), budget)\n\n        # (7) Sampling probabilities re-computed after tightening caps\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Make mask even sparser if most weights are concentrated (top-k style)\n        if False and expwts.numel() > 0:\n            # Estimate for each query: how much of total expwts mass is in top tokens?\n            topk = min(4, sampling_range)\n            sorted_expwts, _ = torch.sort(expwts[..., start_idx:end_idx], dim=-1, descending=True)\n            expwts_sum = expwts[..., start_idx:end_idx].sum(dim=-1, keepdim=True) + 1e-8\n            frac_top = sorted_expwts[..., :topk].sum(dim=-1, keepdim=True) / expwts_sum\n            # If most rows have top-4 covering >60% of the mass, we can make budget even smaller\n            ultra_sparse_condition = (frac_top > 0.6).squeeze(-1)\n            if torch.any(ultra_sparse_condition):\n                budget = torch.where(ultra_sparse_condition, torch.clamp(budget, max=min_base+1), budget)\n            # Recompute probabilities\n            sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Create adaptive mask and merge with previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n", "language": "python", "parent_id": "673e6f4b-ac2f-41b3-90ac-2ea0e23b103b", "generation": 6, "timestamp": 1757489918.8149278, "iteration_found": 47, "metrics": {"density": -0.07208794229862785, "error": -0.03505992889404297, "combined_score": -0.05357393559633541}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: 'budget = torch.ceil(budget.float() * 0.54).long()' to 'budget = torch.ceil(budget.float() * 0.60).long()'\nChange 2: Replace 4 lines with 5 lines\nChange 3: 'if expwts.numel() > 0:' to 'if False and expwts.numel() > 0:'", "parent_metrics": {"density": 100, "error": 100, "combined_score": -100}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert statistician and python / PyTorch programmer specializing statistical analysis \nof approximations. Focus on improving specified algorihm's ability to select the least amount of tokens (entries in the Mask which are non-zero) while maintaining the approximation quality. \nYou have to write the add_mask function using native pytorch operations -- mask created in this function should be as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nThis file is part of a project which is a comprehensive framework designed for implementing and experimenting with various sparse attention mechanisms in deep learning models.  You will be improving on one of the Maskers. \nOverview of Maskers:\nMaskers are the core components that define how attention patterns are computed in the sparse attention framework. They implement different strategies for determining which key-query pairs should be attended to. A sparse attention in this framework is a series of Masker. Each Masker adds tokens that need to be activated in sparse attention. The data structure to store these active tokens is a Mask class. Details of the Mask class are as follows\n### **Mask Class Structure and Functions**\nThe `Mask` class is a sophisticated data structure that represents attention patterns in multiple formats for optimal performance and memory usage. It is a sparse matrix of size `(batch_size, heads, q_len, k_len)` where if an element is 0, that token is inactive for the particular head and query. If it is non-zero, then it is active and the value stores the probability with which the token is sampled. \n#### **Core Attributes:**\n```python\nclass Mask:\n    def __init__(self, shape, dtype, mask=None, indices=None, ptr=None, \n                data=None, from_dense_mask=False, from_index=False, is_full=False):\n        self.shape = shape                    # Shape of the mask (*, n)\n        self.dtype = dtype                    # Data type for mask values\n        self.from_dense_mask = from_dense_mask  # Whether created from dense tensor\n        self.from_index = from_index          # Whether created from sparse indices\n        self.is_full = is_full                # Whether this is a full mask (all 1.0)\n        \n        # Storage attributes (only one is active at a time)\n        self.mask = None      # Dense tensor representation\n        self.indices = None   # Sparse indices\n        self.ptr = None       # Sparse pointer array\n        self.data = None      # Sparse data values\n```\n#### **Mask Class Functions and Signatures:**\n**Creation Methods:**\n```python\n@classmethod\ndef create_full_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a full mask (all elements are 1.0) with optimized representation\n@classmethod\ndef create_mask_from_dense_mask(shape: Tuple[int, ...], mask: torch.Tensor, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from dense mask tensor\n@classmethod\ndef create_mask_from_indices(shape: Tuple[int, ...], indices: torch.Tensor, ptr: torch.Tensor, data: Optional[torch.Tensor] = None, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from sparse indices and pointer representation\n@classmethod\ndef create_from_row_wise_idx(shape: Tuple[int, ...], row_wise_idx: torch.Tensor, data: torch.Tensor, type: str = \"index\", dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from row-wise indices\n@classmethod\ndef create_empty_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32, mask_type: str = \"dense\") -> \"Mask\"\n# Creates a mask object with all values set to zero\n```\n**Access Methods:**\n```python\ndef get_dense_mask(self) -> torch.Tensor\n# Returns the dense mask representation\ndef get_index_mask(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n# Returns the sparse index representation (indices, ptr, data)\ndef apply_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the mask to an input tensor (0 => inactive, >0 => active with weight)\ndef apply_inv_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the inverse mask to an input tensor (output[IDX] = input[IDX] * 1.0 / mask[IDX])\n```\n**Utility Methods:**\n```python\ndef is_full_mask(self) -> bool\n# Checks if this is a full mask (all elements are 1.0)\ndef is_empty(self) -> bool\n# Checks if the mask is empty (all elements are 0.0)\ndef get_density(self) -> float\n# Returns the density/sparsity of the mask (ratio of non-zero elements)\ndef merge_mask(self, other_mask: \"Mask\", inplace: bool = False) -> \"Mask\"\n# Merges this mask with another mask in sparse format\n```\n**Three Representation Formats:**\n1. **Dense Representation** (`from_dense_mask=True`): Full tensor storage for compatibility\n2. **Sparse Representation** (`from_index=True`): CSR-like format for memory efficiency  \n3. **Full Mask Optimization** (`is_full=True`): Zero storage for all-ones masks\nMask is a sparse matrix of size batch_size, heads, q_len, k_len . where if an element is 0, that token is inactive for the particular head and query. if it is non-zero then it is active. The final attention using mask is computed as follows,\n### **`get_masked_attention_output` Function:**\n**Function Signature:**\n```python\ndef get_masked_attention_output(\n    module: nn.Module,\n    queries: torch.Tensor,\n    keys: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: Optional[torch.Tensor],\n    scaling: float,\n    dropout: float,\n    sparse_attention_mask: Mask,\n    return_attention_weights: bool = False,\n    **kwargs: Dict[str, Any],\n) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n```\n**English Description:**\nThis function computes masked attention output by dividing numerator by denominator. It takes the attention module, query/key/value tensors, optional attention mask, scaling factor, dropout probability, and the sparse attention mask object. It optionally returns attention weights along with the output. The function efficiently computes exponential attention weights once and reuses them for both numerator and denominator calculations to avoid redundant computation. **Important**: The function uses `apply_inv_mask` (inverse mask application) during the computation process, which applies the inverse of the mask weights to the attention scores.\n**Key Steps:**\n1. **Compute exponential attention weights** using `_compute_masked_exp_attention_weights`\n2. **Apply inverse mask** using `sparse_attention_mask.apply_inv_mask()` to the exponential attention weights\n3. **Calculate numerator** by multiplying exponential weights with values\n4. **Calculate denominator** by summing exponential weights along the last dimension\n5. **Compute final output** by dividing numerator by denominator\n6. **Optionally return attention weights** by normalizing exponential weights with denominator\n**Return Values:**\n- If `return_attention_weights=False`: Returns attention output tensor of shape `(b, h, sq, d)`\n- If `return_attention_weights=True`: Returns tuple of `(attention_output, attention_weights)` where attention_weights has shape `(b, h, sq, sk)`\nYou are supposed to write add_mask function for this class which decides what tokens are active and what weights are associated with them . The `add_mask` function is the core method in every masker that defines how attention patterns are computed and applied. It serves as the primary interface between the attention mechanism and the masking logic.\n### **Function Signature:**\n```python\ndef add_mask(\n    self,\n    keys: torch.Tensor,\n    queries: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: torch.Tensor,\n    scaling: float,\n    dropout: float,\n    sparse_meta_data: Dict[Any, Any],\n    previous_mask: Mask,\n    **kwargs: Dict[str, Any],\n) -> Mask:\n```\n### **Key Responsibilities:**\n1. **Pattern Computation**: Determines which key-query pairs should be attended to based on the masker's strategy\n2. **Mask Generation**: Creates a `Mask` object representing the computed attention pattern\n3. **Mask Merging**: Combines the new mask with any previous masks to build cumulative attention patterns\nImportant things to remember: Use query and key head computation to compute num_groups and use that to repeat keys before you use them. \n\nFocus on evolving the add_mask function to produce the best makser possible that is as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nExplain step-by-step the reasoning process for your solution and how this will lead to a better masker.\n", "user": "# Current Program Information\n- Current performance metrics: - density: 100.0000\n- error: 100.0000\n- combined_score: -100.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: density, error. Consider continuing with similar changes.\n- Metrics showing regression: combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: density: -0.0653, error: -0.0510, combined_score: -0.0581\n- Outcome: Regression in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: density: -0.0748, error: -0.0351, combined_score: -0.0550\n- Outcome: Regression in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: density: -0.0702, error: -0.0397, combined_score: -0.0550\n- Outcome: Regression in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: -0.0550)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Add an adaptive sparse attention mask by aggressively shrinking budget while \n        retaining statistical guarantees, simplifying the code for maintainability.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Dynamically adapt parameters for sequence length (tuned for higher sparsity)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.16\n            self.delta = 0.14\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.18\n            self.delta = 0.17\n        else:\n            self.base_rate_sampling = 0.01\n            self.epsilon = 0.2\n            self.delta = 0.2\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Precompute delta PPF once\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights (after masking)\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Sampling budget setup ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Statistical, error\u2013controlled budget (pre-sparsification)\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ------------------------------------------------------------------ #\n        #  Improved sparsification strategy (empirically best so far)\n        # ------------------------------------------------------------------ #\n        # 1) More aggressive but stable scaling\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # 2) Safer per-row lower-bound (helps variance estimation)\n        min_budget = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_budget)\n\n        # 3) Hard upper-cap : \u2264 8 % of available keys\n        max_budget = max(min_budget, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # 4) Extra lower-safety for extremely short windows\n        budget = torch.clamp(budget, min=2)\n\n        # 5) If static denominator already large, allow even sparser rows\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(\n                budget, max=max(min_budget, int(0.06 * sampling_range))\n            )\n\n        # Updated sampling probabilities\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Compose the new adaptive mask\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        # Merge with any previous mask\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0702), Performs well on error (-0.0397), Performs well on combined_score (-0.0550)\n\n\n### Program 2 (Score: -0.0550)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 enhanced sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n        # (1) Row-wise adaptive shrink based on coefficient of variation.\n        #     If the relative std-dev is small, far fewer extra samples are required.\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink_factor = torch.where(rel_std < 0.25, 0.50, 1.00)  # 50 % cut for stable rows\n\n        # (2) Global soft shrink (slightly stronger than before)\n        budget = torch.ceil(budget.float() * 0.80 * shrink_factor).long()\n\n        # (3) Respect lower-bound for numerical stability\n        budget = torch.clamp(budget, min=num_base_samples)\n\n        # (4) Hard cap: at most 12 % of the available keys per row\n        max_budget = max(num_base_samples, int(0.12 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Re-compute sampling probabilities after final budget adjustment\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Create adaptive mask and merge with the previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0748), Performs well on error (-0.0351), Performs well on combined_score (-0.0550)\n\n\n### Program 3 (Score: -0.0581)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: Combine very aggressive top-k selection with tighter statistical random sampling to maximize sparsity\n        while maintaining attention approximation quality, using all-native torch operations.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        seq_len_keys = keys.shape[-2]\n        # Tighter statistical parameters for more aggressive sparsity\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.008\n            self.epsilon = 0.13\n            self.delta = 0.11\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.009\n            self.epsilon = 0.15\n            self.delta = 0.12\n        else:\n            self.base_rate_sampling = 0.01\n            self.epsilon = 0.16\n            self.delta = 0.13\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # (1) Highly aggressive top-k deterministic mask\n        topk_ratio = 0.025 if seq_len_keys > 4000 else 0.037\n        k = max(num_base_samples, int(topk_ratio * sampling_range))\n        topk_vals, topk_idx = torch.topk(\n            expwts, k=k, dim=-1, largest=True, sorted=False\n        )\n        topk_data = torch.ones_like(topk_idx, dtype=previous_mask.dtype)\n        topk_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=topk_idx,\n            data=topk_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        # (2) Statistical sampling for \"tail\" coverage (tiny budget, tighter bounds)\n        base_row_wise_idx = torch.randint(\n            low=0,\n            high=sampling_range,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True).clamp(min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n        min_budget = num_base_samples\n        max_budget = max(num_base_samples, int(0.06 * sampling_range))\n        budget = torch.clamp(torch.ceil(budget_squared * 0.39).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        very_low_var_mask = (std_estimate.squeeze(-1) < 1e-8)\n        if torch.any(very_low_var_mask):\n            budget = torch.where(\n                very_low_var_mask, \n                torch.full_like(budget, min_budget), \n                budget\n            )\n            sampling_probabilities = torch.where(\n                very_low_var_mask, \n                torch.full_like(sampling_probabilities, min_budget/sampling_range), \n                sampling_probabilities\n            )\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        # Hybrid mask: always include union of aggressive top-k and statistical coverage\n        merged_mask = previous_mask.merge_mask(topk_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0653), Performs well on error (-0.0510), Performs well on combined_score (-0.0581)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -0.0595)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Improved: More aggressive sparsification with top-k + statistical coverage hybrid.\n        1. Use top-k (per row) on exp attention weights to always cover most relevant tokens (fewest needed for quality).\n        2. Additionally sample by statistical budget as in original, but shrink per-row maximum more aggressively.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        seq_len_keys = keys.shape[-2]\n\n        # Dynamic settings for higher sparsity for all seq lengths\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.22\n        self.delta = 0.17\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # -- Range for sampling --\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # ---- (1) Top-k deterministic mask for each row ----\n        # - Each row (b, h, q) selects k tokens with largest expwts.\n        # - k is much smaller than sampling_range for sparsity.\n        # - The top-k picks are assigned weight=1 for best approximation.\n        topk_ratio = 0.035 if seq_len_keys >= 4096 else 0.045\n        k = max(num_base_samples, int(topk_ratio * sampling_range))\n\n        # topk indices/values (native torch, per row)\n        topk_vals, topk_idx = torch.topk(\n            expwts, k=k, dim=-1, largest=True, sorted=False\n        )\n        topk_data = torch.ones_like(topk_idx, dtype=previous_mask.dtype)\n        topk_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=topk_idx,\n            data=topk_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ---- (2) Statistically adaptive random mask (as in original, but harder capped max) ----\n        base_row_wise_idx = torch.randint(\n            low=0,\n            high=sampling_range,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Budget: cap more aggressively\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n        # Lower min, much lower max\n        min_budget = num_base_samples\n        max_budget = max(num_base_samples, int(0.08 * sampling_range))\n        budget = torch.clamp(torch.ceil(budget_squared * 0.55).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Remove mask entirely for near-zero budget (ultra sparse bonus)\n        zero_budget = (budget == 0)\n        if torch.any(zero_budget):\n            budget = budget.masked_fill(zero_budget, 0)\n            sampling_probabilities = sampling_probabilities.masked_fill(zero_budget, 0)\n\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge masks: topk OR adaptive mask (union). This covers both dominant (topk) and tail (statistical random) tokens.\n        merged_mask = previous_mask.merge_mask(topk_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n\n### Program D2 (Score: -0.0592)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Improved: More aggressive sparsification with top-k + statistical coverage hybrid.\n        1. Use top-k (per row) on exp attention weights to always cover most relevant tokens (fewest needed for quality).\n        2. Additionally sample by statistical budget as in original, but shrink per-row maximum more aggressively.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        seq_len_keys = keys.shape[-2]\n\n        # Dynamic settings for higher sparsity for all seq lengths\n        # Slightly increase the minimum random sampling and tighten error bounds\n        # to improve approximation quality with marginal density cost\n        self.base_rate_sampling = 0.008\n        self.epsilon = 0.18\n        self.delta = 0.15\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # -- Range for sampling --\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # ---- (1) Top-k deterministic mask for each row ----\n        # - Each row (b, h, q) selects k tokens with largest expwts.\n        # - k is much smaller than sampling_range for sparsity.\n        # - The top-k picks are assigned weight=1 for best approximation.\n        # Cover a bit more mass in each row to reduce approximation error\n        topk_ratio = 0.040 if seq_len_keys >= 4096 else 0.050\n        k = max(num_base_samples, int(topk_ratio * sampling_range))\n\n        # topk indices/values (native torch, per row)\n        topk_vals, topk_idx = torch.topk(\n            expwts, k=k, dim=-1, largest=True, sorted=False\n        )\n        topk_data = torch.ones_like(topk_idx, dtype=previous_mask.dtype)\n        topk_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=topk_idx,\n            data=topk_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ---- (2) Statistically adaptive random mask (as in original, but harder capped max) ----\n        base_row_wise_idx = torch.randint(\n            low=0,\n            high=sampling_range,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Budget: cap more aggressively\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n        # Lower min, much lower max\n        min_budget = num_base_samples\n        # Allow a slightly larger upper-cap to reduce error on difficult rows\n        max_budget = max(num_base_samples, int(0.10 * sampling_range))\n        # Use a more conservative shrink factor to trade a bit of density for lower error\n        budget = torch.clamp(torch.ceil(budget_squared * 0.65).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Remove mask entirely for near-zero budget (ultra sparse bonus)\n        zero_budget = (budget == 0)\n        if torch.any(zero_budget):\n            budget = budget.masked_fill(zero_budget, 0)\n            sampling_probabilities = sampling_probabilities.masked_fill(zero_budget, 0)\n\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge masks: topk OR adaptive mask (union). This covers both dominant (topk) and tail (statistical random) tokens.\n        merged_mask = previous_mask.merge_mask(topk_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: -0.0550, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Add an adaptive sparse attention mask by aggressively shrinking budget while \n        retaining statistical guarantees, simplifying the code for maintainability.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Dynamically adapt parameters for sequence length (tuned for higher sparsity)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.16\n            self.delta = 0.14\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.18\n            self.delta = 0.17\n        else:\n            self.base_rate_sampling = 0.01\n            self.epsilon = 0.2\n            self.delta = 0.2\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Precompute delta PPF once\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights (after masking)\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Sampling budget setup ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Statistical, error\u2013controlled budget (pre-sparsification)\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ------------------------------------------------------------------ #\n        #  Improved sparsification strategy (empirically best so far)\n        # ------------------------------------------------------------------ #\n        # 1) More aggressive but stable scaling\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # 2) Safer per-row lower-bound (helps variance estimation)\n        min_budget = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_budget)\n\n        # 3) Hard upper-cap : \u2264 8 % of available keys\n        max_budget = max(min_budget, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # 4) Extra lower-safety for extremely short windows\n        budget = torch.clamp(budget, min=2)\n\n        # 5) If static denominator already large, allow even sparser rows\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(\n                budget, max=max(min_budget, int(0.06 * sampling_range))\n            )\n\n        # Updated sampling probabilities\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Compose the new adaptive mask\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        # Merge with any previous mask\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 19 lines with 30 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 2 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # Shrink factor that trades accuracy for sparsity (0.7-0.8 is typical)\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        # ------------------------------------------------------------------ #\n        #  \u2728  REWRITTEN SPARSIFICATION LOGIC (leader-board proven)          #\n        # ------------------------------------------------------------------ #\n        # We drop the former \u201ctop-mass + tail\u201d strategy that turned out to\n        # activate far too many tokens (100 % density!) and replace it with\n        # the compact adaptive sampler that obtained the best density/error\n        # numbers in earlier submissions.\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # ---------- dynamic hyper-parameters wrt sequence length ---------- #\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10_000:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.02, 0.20, 0.20\n        elif seq_len_keys > 5_000:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.018, 0.22, 0.22\n        else:\n            self.base_rate_sampling, self.epsilon, self.delta = 0.015, 0.25, 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If the existing mask is already dense we do nothing.\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # ---------- shapes & stable exp-attention  ---------- #\n        dims = self._extract_tensor_dimensions(keys, queries)\n        b, h, sq, sk = dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        expwts = self._compute_exp_attention_scores(queries, keys, scaling, attention_mask)\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # ---------- base sampling for variance estimate ---------- #\n        start, end, span = self._get_sampling_range(sk)\n        n_base = self._get_base_sample_count(span)\n        base_mask, std_est = self._get_std_estimate_using_base_sample(\n            expwts, b, h, sq, sk, start, end, n_base, previous_mask.dtype\n        )\n        samp_den = apply_inv_mask_sum(expwts, base_mask)\n        est_den  = static_denominator + samp_den\n\n        # ---------- statistical budget & sparsity boosts ---------- #\n        budget = self._compute_adaptive_budget(std_est, est_den, span)\n        budget = torch.ceil(budget.float() * 0.54).long()          # global shrink\n        min_b  = max(n_base, 4)\n        max_b  = max(min_b, int(0.08 * span))\n        budget = torch.clamp(budget, min=min_b, max=max_b)\n        if torch.median(static_denominator) > 5.0:                 # extra reduction\n            budget = torch.clamp(budget, max=max(min_b, int(0.06 * span)))\n        budget = torch.clamp(budget, min=2)\n\n        # ---------- build sparse mask ---------- #\n        probs = (budget / span).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget, sampling_probability=probs,\n            seq_len_keys=sk, start_idx=start, end_idx=end, dtype=previous_mask.dtype\n        )\n\n        # ---------- merge & early-return ---------- #\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # NOTE: the legacy \u201ctop-mass + tail\u201d implementation that follows\n        # is now unreachable but retained for reference.\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 3 samples since it is used for std estimation\n        # (two samples often yield zero variance and unstable budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: top-k high-mass coverage plus aggressive adaptive budget for optimal sparsity and quality.\n\n        - First, select the minimum number of tokens per row (query) that account for at least 98% of exp(atten) mass.\n        - Then, for any long-tail, sample adaptively with an aggressive statistical error budget.\n        - This minimizes density while preserving near-full attention approximation.\n\n        The mask is the union of: (a) high-mass top-k mask, (b) adaptive random mask, (c) any previous mask.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # More aggressive static for all seq lens, keeping parameterization stable\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.18\n        self.delta = 0.14\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --------------- (1) Top-mass coverage ---------------\n        # For each (b, h, q), find minimum k s.t. cumsum(expwts) covers \u226598% of row mass.\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.98).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for extreme cases for sparsity\n        max_topk = min(16, seq_len_keys // 8)\n        k1 = torch.clamp(k1, min=2, max=max_topk)\n\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail sampling as before, but with more sparsity\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Even more aggressively capped for long tails\n        min_budget = num_base_samples\n        max_budget = max(min_budget, int(0.05 * sampling_range))\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        # Ultra sparse for low-variance rows\n        shrink = torch.where(rel_std < 0.13, 0.27, 0.53)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # For rows with nearly flat dist, skip tail sampling (use only top-mass, keep at least min_budget)\n        flat_row = (rel_std < 0.05).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n            sampling_probabilities = torch.where(\n                flat_row, torch.full_like(sampling_probabilities, min_budget/sampling_range), sampling_probabilities\n            )\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 2 lines with 63 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 3 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Improved hybrid: adaptive top-mass (per-row) + aggressive tail coverage.\n        1. For each row, find minimum top-k covering ~98% of mass, use these for main mask.\n        2. For long tail, use tighter/row-adaptive budget for statistical coverage.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        seq_len_keys = keys.shape[-2]\n\n        # Aggressive settings for both density and error; hard top-mass, tighter tail\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.19\n        self.delta = 0.13\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # Early exit if mask is already full\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # ----------- (1) Top-mass mask: minimal set to cover ~98% attention mass ---------------\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        # Find per-row k s.t. cumulative mass >= 0.98\n        topk_mass = 0.98\n        k1 = (mass_frac < topk_mass).sum(dim=-1, keepdim=True) + 1\n        max_topk = min(12, seq_len_keys // 10)  # Encourage minimality\n        k1 = torch.clamp(k1, min=2, max=max_topk)\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask, expanded_sorted_idx, torch.zeros_like(expanded_sorted_idx)\n        )\n        k1_data = torch.where(\n            k1_mask, torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype), torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ----------- (2) Statistically adaptive tail mask, but aggressively clamped ---------\n        base_row_wise_idx = torch.randint(\n            low=0,\n            high=sampling_range,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True).clamp(min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink = torch.where(rel_std < 0.17, 0.18, 0.54)\n        min_budget = num_base_samples\n        max_budget = max(num_base_samples, int(0.06 * sampling_range))\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # For ultra-flat rows, reduce budget even more\n        ultra_flat = (rel_std < 0.07).squeeze(-1)\n        if torch.any(ultra_flat):\n            budget = torch.where(ultra_flat, torch.full_like(budget, min_budget), budget)\n            sampling_probabilities = torch.where(ultra_flat, torch.full_like(sampling_probabilities, min_budget/sampling_range), sampling_probabilities)\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ----------- Merge both: top-mass \u222a adaptive tail \u222a previous -----------------------\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 130 lines with 127 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 4 (Score: -0.0730, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Add an adaptive sparse attention mask by aggressively shrinking budget while \n        retaining statistical guarantees, simplifying the code for maintainability.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # Dynamically adapt parameters for sequence length (tuned for higher sparsity)\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.015\n            self.epsilon = 0.16\n            self.delta = 0.14\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.012\n            self.epsilon = 0.18\n            self.delta = 0.17\n        else:\n            self.base_rate_sampling = 0.01\n            self.epsilon = 0.2\n            self.delta = 0.2\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Precompute delta PPF once\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        # If fully dense mask already, no further sparsification is required\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        # Compute stable exp attention weights (after masking)\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --- Sampling budget setup ---\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        # Base sampling + std estimation\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        # Statistical error-controlled budget (pre-sparsification)\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # Enhanced sparsification steps:\n        # (1) More aggressively shrink budget for higher sparsity, but not too much\n        budget = torch.ceil(budget.float() * 0.55).long()\n        # (2) Use the true minimum base sample, but also slightly reduce max_budget to 10% of keys for more sparsity\n        min_budget = num_base_samples\n        max_budget = max(num_base_samples, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, min=min_budget, max=max_budget)\n\n        # (3) Set sampling probability, but introduce soft min cutoff for low budget rows\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Bonus: skip rows where expwts variance is extremely low (i.e., not contributing much to denominator)\n        # This is a soft-hard threshold: if std_estimate is tiny, mask out that row (leave only base sample)\n        very_low_var_mask = (std_estimate.squeeze(-1) < 1e-7)\n        if torch.any(very_low_var_mask):\n            budget = torch.where(\n                very_low_var_mask, \n                torch.full_like(budget, min_budget), \n                budget\n            )\n            sampling_probabilities = torch.where(\n                very_low_var_mask, \n                torch.full_like(sampling_probabilities, min_budget/sampling_range), \n                sampling_probabilities\n            )\n\n        # Compose the new adaptive mask\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        # Merge with any previous mask\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 31 lines with 41 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 5 (Score: -0.0550, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 enhanced sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n        # (1) Row-wise adaptive shrink based on coefficient of variation.\n        #     If the relative std-dev is small, far fewer extra samples are required.\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        shrink_factor = torch.where(rel_std < 0.25, 0.50, 1.00)  # 50 % cut for stable rows\n\n        # (2) Global soft shrink (slightly stronger than before)\n        budget = torch.ceil(budget.float() * 0.80 * shrink_factor).long()\n\n        # (3) Respect lower-bound for numerical stability\n        budget = torch.clamp(budget, min=num_base_samples)\n\n        # (4) Hard cap: at most 12 % of the available keys per row\n        max_budget = max(num_base_samples, int(0.12 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Re-compute sampling probabilities after final budget adjustment\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Create adaptive mask and merge with the previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 12 lines with 17 lines, Alternative density approach, Alternative error approach\n\n\n\n# Current Program\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n\n        # --- DENSITY-BOOSTING STRATEGY ---\n        # Make budget scaling adaptive based on error feedback if available, or use more aggressive static scaling.\n        # Aim: Reduce density without hurting error.\n\n        # (1) Scale budget more aggressively (tuned lower empirically).\n        budget = torch.ceil(budget.float() * 0.54).long()\n\n        # (2) Use slightly higher minimum base (helps std and very sparse zones)\n        min_base = max(num_base_samples, 4)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) Tighter cap: at most 5% of available keys per row (was 6%)\n        max_budget = max(min_base, int(0.05 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Enforce a sensible minimum (2 for very short sequence regions)\n        budget = torch.clamp(budget, min=2)\n\n        # (5) If static_denominator is very large, lower sampling even more for ultra-sparse attention\n        if torch.median(static_denominator) > 5.0:\n            budget = torch.clamp(budget, max=max(min_base, int(0.03 * sampling_range)))\n\n        # (6) Prune budget to zero for very low estimated_denominator (ultra-sparse)\n        # Reduce budget where estimated_denominator < 0.02 * static_denominator.max()\n        if estimated_denominator is not None:\n            min_mask_threshold = 0.02 * static_denominator.max()\n            mask_sparse_rows = (estimated_denominator < min_mask_threshold)\n            if torch.any(mask_sparse_rows):\n                budget = budget.masked_fill(mask_sparse_rows, 0)\n\n        # (7) Sampling probabilities re-computed after tightening caps\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Make mask even sparser if most weights are concentrated (top-k style)\n        if expwts.numel() > 0:\n            # Estimate for each query: how much of total expwts mass is in top tokens?\n            topk = min(4, sampling_range)\n            sorted_expwts, _ = torch.sort(expwts[..., start_idx:end_idx], dim=-1, descending=True)\n            expwts_sum = expwts[..., start_idx:end_idx].sum(dim=-1, keepdim=True) + 1e-8\n            frac_top = sorted_expwts[..., :topk].sum(dim=-1, keepdim=True) / expwts_sum\n            # If most rows have top-4 covering >60% of the mass, we can make budget even smaller\n            ultra_sparse_condition = (frac_top > 0.6).squeeze(-1)\n            if torch.any(ultra_sparse_condition):\n                budget = torch.where(ultra_sparse_condition, torch.clamp(budget, max=min_base+1), budget)\n            # Recompute probabilities\n            sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # Create adaptive mask and merge with previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["We need to reduce dense mask by modifying new sparsification section; keep stable budgets; Remove aggressive pruning to zero and heavy topk; change budget scaling to 0.60; modify mask_sparse_rows to set min_base instead of zero; disable expwts sort code (set to False). Provide multiple diff blocks:\n\n1. Replace budget scaling line.\n\n2. Replace mask_sparse_rows block.\n\n3. Disable topk block by adding False.\n\nDiffs:\n\nBlock1:\n\n<<<<<<< SEARCH\n        budget = torch.ceil(budget.float() * 0.54).long()\n=======\n        budget = torch.ceil(budget.float() * 0.60).long()\n>>>>>>> REPLACE\n\nBlock2:\n\n<<<<<<< SEARCH\n            min_mask_threshold = 0.02 * static_denominator.max()\n            mask_sparse_rows = (estimated_denominator < min_mask_threshold)\n            if torch.any(mask_sparse_rows):\n                budget = budget.masked_fill(mask_sparse_rows, 0)\n=======\n            # Keep a minimal budget for rows with tiny denominator instead of dropping them completely\n            min_mask_threshold = 0.02 * static_denominator.max()\n            mask_sparse_rows = (estimated_denominator < min_mask_threshold)\n            if torch.any(mask_sparse_rows):\n                budget = torch.where(mask_sparse_rows, torch.full_like(budget, min_base), budget)\n>>>>>>> REPLACE\n\nBlock3:\n\n<<<<<<< SEARCH\n        if expwts.numel() > 0:\n=======\n        if False and expwts.numel() > 0:\n>>>>>>> REPLACE\n\nThese replacements should avoid zero budgets that might cause fallback to dense mask, reduce computational heavy sorting, yield sparse yet valid mask, hopefully improving density and error metrics."]}}}