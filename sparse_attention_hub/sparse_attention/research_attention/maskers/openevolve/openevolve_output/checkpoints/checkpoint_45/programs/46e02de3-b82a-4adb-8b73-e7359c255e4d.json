{"id": "46e02de3-b82a-4adb-8b73-e7359c255e4d", "code": "\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ------------------------------------------------------------------ #\n        # Improved: Hybrid deterministic top-mass + aggressive adaptive tail\n        # ------------------------------------------------------------------ #\n\n        # (1) Deterministic selection: minimal top-k to cover 98% exp(attn) mass\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        k_98 = (cumsum / (total + 1e-8) < 0.98).sum(dim=-1, keepdim=True) + 1\n        # Safety: at least 2, cap to 16 for memory efficiency\n        k_98 = torch.clamp(k_98, min=2, max=min(16, seq_len_keys // 8))\n        max_topk = int(k_98.max())\n        rows = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = rows < k_98\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # (2) Adaptive statistical tail (aggressive)\n        # shrink theoretical budget further, but not lower than strict minimum for stability\n        min_base = max(num_base_samples, 3)\n        scale = torch.where((cumsum[..., -1:] / (static_denominator + 1e-8)) > 0.98, 0.40, 0.62)\n        # If most of the mass is already covered, shrink the tail aggressively\n\n        budget = torch.ceil(budget.float() * scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Ignore tail for very-short rows (where 98% mass < 4 tokens)\n        budget = torch.where(k_98 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Final: mask is (prev \u222a top-mass \u222a tail)\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n", "language": "python", "parent_id": "a59a0827-3ca6-42f8-8ff7-a5476a908415", "generation": 2, "timestamp": 1757487874.0106773, "iteration_found": 32, "metrics": {"density": -0.0723678835638054, "error": -0.035253047943115234, "combined_score": -0.05381046575346032}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 32 lines with 56 lines", "parent_metrics": {"density": -0.07469072640223624, "error": -0.03505873680114746, "combined_score": -0.05487473160169185}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert statistician and python / PyTorch programmer specializing statistical analysis \nof approximations. Focus on improving specified algorihm's ability to select the least amount of tokens (entries in the Mask which are non-zero) while maintaining the approximation quality. \nYou have to write the add_mask function using native pytorch operations -- mask created in this function should be as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nThis file is part of a project which is a comprehensive framework designed for implementing and experimenting with various sparse attention mechanisms in deep learning models.  You will be improving on one of the Maskers. \nOverview of Maskers:\nMaskers are the core components that define how attention patterns are computed in the sparse attention framework. They implement different strategies for determining which key-query pairs should be attended to. A sparse attention in this framework is a series of Masker. Each Masker adds tokens that need to be activated in sparse attention. The data structure to store these active tokens is a Mask class. Details of the Mask class are as follows\n### **Mask Class Structure and Functions**\nThe `Mask` class is a sophisticated data structure that represents attention patterns in multiple formats for optimal performance and memory usage. It is a sparse matrix of size `(batch_size, heads, q_len, k_len)` where if an element is 0, that token is inactive for the particular head and query. If it is non-zero, then it is active and the value stores the probability with which the token is sampled. \n#### **Core Attributes:**\n```python\nclass Mask:\n    def __init__(self, shape, dtype, mask=None, indices=None, ptr=None, \n                data=None, from_dense_mask=False, from_index=False, is_full=False):\n        self.shape = shape                    # Shape of the mask (*, n)\n        self.dtype = dtype                    # Data type for mask values\n        self.from_dense_mask = from_dense_mask  # Whether created from dense tensor\n        self.from_index = from_index          # Whether created from sparse indices\n        self.is_full = is_full                # Whether this is a full mask (all 1.0)\n        \n        # Storage attributes (only one is active at a time)\n        self.mask = None      # Dense tensor representation\n        self.indices = None   # Sparse indices\n        self.ptr = None       # Sparse pointer array\n        self.data = None      # Sparse data values\n```\n#### **Mask Class Functions and Signatures:**\n**Creation Methods:**\n```python\n@classmethod\ndef create_full_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a full mask (all elements are 1.0) with optimized representation\n@classmethod\ndef create_mask_from_dense_mask(shape: Tuple[int, ...], mask: torch.Tensor, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from dense mask tensor\n@classmethod\ndef create_mask_from_indices(shape: Tuple[int, ...], indices: torch.Tensor, ptr: torch.Tensor, data: Optional[torch.Tensor] = None, dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from sparse indices and pointer representation\n@classmethod\ndef create_from_row_wise_idx(shape: Tuple[int, ...], row_wise_idx: torch.Tensor, data: torch.Tensor, type: str = \"index\", dtype: torch.dtype = torch.float32) -> \"Mask\"\n# Creates a Mask from row-wise indices\n@classmethod\ndef create_empty_mask(shape: Tuple[int, ...], dtype: torch.dtype = torch.float32, mask_type: str = \"dense\") -> \"Mask\"\n# Creates a mask object with all values set to zero\n```\n**Access Methods:**\n```python\ndef get_dense_mask(self) -> torch.Tensor\n# Returns the dense mask representation\ndef get_index_mask(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n# Returns the sparse index representation (indices, ptr, data)\ndef apply_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the mask to an input tensor (0 => inactive, >0 => active with weight)\ndef apply_inv_mask(self, input_tensor: torch.Tensor) -> torch.Tensor\n# Applies the inverse mask to an input tensor (output[IDX] = input[IDX] * 1.0 / mask[IDX])\n```\n**Utility Methods:**\n```python\ndef is_full_mask(self) -> bool\n# Checks if this is a full mask (all elements are 1.0)\ndef is_empty(self) -> bool\n# Checks if the mask is empty (all elements are 0.0)\ndef get_density(self) -> float\n# Returns the density/sparsity of the mask (ratio of non-zero elements)\ndef merge_mask(self, other_mask: \"Mask\", inplace: bool = False) -> \"Mask\"\n# Merges this mask with another mask in sparse format\n```\n**Three Representation Formats:**\n1. **Dense Representation** (`from_dense_mask=True`): Full tensor storage for compatibility\n2. **Sparse Representation** (`from_index=True`): CSR-like format for memory efficiency  \n3. **Full Mask Optimization** (`is_full=True`): Zero storage for all-ones masks\nMask is a sparse matrix of size batch_size, heads, q_len, k_len . where if an element is 0, that token is inactive for the particular head and query. if it is non-zero then it is active. The final attention using mask is computed as follows,\n### **`get_masked_attention_output` Function:**\n**Function Signature:**\n```python\ndef get_masked_attention_output(\n    module: nn.Module,\n    queries: torch.Tensor,\n    keys: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: Optional[torch.Tensor],\n    scaling: float,\n    dropout: float,\n    sparse_attention_mask: Mask,\n    return_attention_weights: bool = False,\n    **kwargs: Dict[str, Any],\n) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n```\n**English Description:**\nThis function computes masked attention output by dividing numerator by denominator. It takes the attention module, query/key/value tensors, optional attention mask, scaling factor, dropout probability, and the sparse attention mask object. It optionally returns attention weights along with the output. The function efficiently computes exponential attention weights once and reuses them for both numerator and denominator calculations to avoid redundant computation. **Important**: The function uses `apply_inv_mask` (inverse mask application) during the computation process, which applies the inverse of the mask weights to the attention scores.\n**Key Steps:**\n1. **Compute exponential attention weights** using `_compute_masked_exp_attention_weights`\n2. **Apply inverse mask** using `sparse_attention_mask.apply_inv_mask()` to the exponential attention weights\n3. **Calculate numerator** by multiplying exponential weights with values\n4. **Calculate denominator** by summing exponential weights along the last dimension\n5. **Compute final output** by dividing numerator by denominator\n6. **Optionally return attention weights** by normalizing exponential weights with denominator\n**Return Values:**\n- If `return_attention_weights=False`: Returns attention output tensor of shape `(b, h, sq, d)`\n- If `return_attention_weights=True`: Returns tuple of `(attention_output, attention_weights)` where attention_weights has shape `(b, h, sq, sk)`\nYou are supposed to write add_mask function for this class which decides what tokens are active and what weights are associated with them . The `add_mask` function is the core method in every masker that defines how attention patterns are computed and applied. It serves as the primary interface between the attention mechanism and the masking logic.\n### **Function Signature:**\n```python\ndef add_mask(\n    self,\n    keys: torch.Tensor,\n    queries: torch.Tensor,\n    values: torch.Tensor,\n    attention_mask: torch.Tensor,\n    scaling: float,\n    dropout: float,\n    sparse_meta_data: Dict[Any, Any],\n    previous_mask: Mask,\n    **kwargs: Dict[str, Any],\n) -> Mask:\n```\n### **Key Responsibilities:**\n1. **Pattern Computation**: Determines which key-query pairs should be attended to based on the masker's strategy\n2. **Mask Generation**: Creates a `Mask` object representing the computed attention pattern\n3. **Mask Merging**: Combines the new mask with any previous masks to build cumulative attention patterns\nImportant things to remember: Use query and key head computation to compute num_groups and use that to repeat keys before you use them. \n\nFocus on evolving the add_mask function to produce the best makser possible that is as sparse as possible while preserving the ouptut of full attention as much as possible.\n\nExplain step-by-step the reasoning process for your solution and how this will lead to a better masker.\n", "user": "# Current Program Information\n- Current performance metrics: - density: -0.0747\n- error: -0.0351\n- combined_score: -0.0549\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: density, error, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: density: -0.0738, error: -0.0349, combined_score: -0.0544\n- Outcome: Regression in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: density: -0.0739, error: -0.0348, combined_score: -0.0543\n- Outcome: Regression in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: density: -0.0735, error: -0.0350, combined_score: -0.0543\n- Outcome: Regression in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: -0.0543)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        # Make sparsification more aggressive; lower scale, and cap budget per row\n        # By adding a deterministic top-k token we can safely shrink the\n        # statistical budget a bit further.\n        scale = 0.55\n        budget = torch.ceil(budget.float() * scale).long()\n\n        # Always ensure at least 2 per row (no degenerate rows)\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # Cap: at most 10% of available keys per query, but no less than min_base\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        budget = torch.clamp(budget, min=2)  # extra lower-bound\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Deterministic top-k inclusion to capture the highest attention mass\n        # ------------------------------------------------------------------ #\n        topk = 1  # single strongest key per (b,h,q)\n        _ , top_indices = torch.topk(expwts, k=topk, dim=-1, largest=True)\n        top_data = torch.ones_like(top_indices, dtype=previous_mask.dtype)\n\n        topk_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_indices,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Merge: previous  \u222a  top-k  \u222a  adaptive\n        # ------------------------------------------------------------------ #\n        merged = previous_mask.merge_mask(topk_mask, inplace=False)\n        merged = merged.merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0735), Performs well on error (-0.0350), Performs well on combined_score (-0.0543)\n\n\n### Program 2 (Score: -0.0543)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n\n        # (1) Aggressively shrink the statistical budget\n        budget = torch.ceil(budget.float() * 0.62).long()\n\n        # (2) Increase base sample count for better std estimation at low density\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) More aggressive cap: at most 10 % of the available keys per row\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Set even lower bound for budget for short sequence regions\n        budget = torch.clamp(budget, min=2)\n\n        # Re-compute sampling probabilities after final budget adjustment\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Create adaptive mask and merge with the previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0739), Performs well on error (-0.0348), Performs well on combined_score (-0.0543)\n\n\n### Program 3 (Score: -0.0544)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ------------------------------------------------------------------ #\n        # Extra sparsification while preserving quality\n        # ------------------------------------------------------------------ #\n        # 1) shrink theoretical budget more aggressively (empirically 0.62\n        #     leads to lower density with negligible loss in accuracy)\n        budget = torch.ceil(budget.float() * 0.62).long()\n\n        # 2) ensure sufficient samples for variance estimation (>=3)\n        min_budget = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_budget)\n\n        # 3) stricter cap \u2013 at most 10 % of the candidate keys\n        max_budget = max(min_budget, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Merge with previous mask and return\n        # ------------------------------------------------------------------ #\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Performs well on density (-0.0738), Performs well on error (-0.0349), Performs well on combined_score (-0.0544)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -0.0544)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        # Make sparsification more aggressive; lower scale, and cap budget per row\n        scale = 0.62\n        budget = torch.ceil(budget.float() * scale).long()\n\n        # Always ensure at least 2 per row (no degenerate rows)\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # Cap: at most 10% of available keys per query, but no less than min_base\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        budget = torch.clamp(budget, min=2)  # extra lower-bound\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge the newly created mask with the previous one\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n\n### Program D2 (Score: -0.0544)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # Shrink factor that trades accuracy for sparsity (0.7-0.8 is typical)\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 3 samples since it is used for std estimation\n        # (two samples often yield zero variance and unstable budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ----------------------------------------------------------- #\n        # Sparsification heuristics\n        #   1. Shrink the theoretical budget by an empirically tuned factor (0.62).\n        #   2. Ensure minimum budget for stability, at least 3 samples.\n        #   3. Hard cap to 10% of keys, but not lower than minimum.\n        #   4. Extra lower bound for ultra-short sequence regions.\n        # ----------------------------------------------------------- #\n        scale = 0.62\n        min_base = max(num_base_samples, 3)\n        budget = torch.ceil(budget.float() * scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        budget = torch.clamp(budget, min=2)  # Extra lower-bound\n\n        # Compute sampling probabilities and create the adaptive mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n        # Merge with previous mask and return\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nKey features: Alternative approach to density, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: -0.0543, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        # Make sparsification more aggressive; lower scale, and cap budget per row\n        # By adding a deterministic top-k token we can safely shrink the\n        # statistical budget a bit further.\n        scale = 0.55\n        budget = torch.ceil(budget.float() * scale).long()\n\n        # Always ensure at least 2 per row (no degenerate rows)\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # Cap: at most 10% of available keys per query, but no less than min_base\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        budget = torch.clamp(budget, min=2)  # extra lower-bound\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Deterministic top-k inclusion to capture the highest attention mass\n        # ------------------------------------------------------------------ #\n        topk = 1  # single strongest key per (b,h,q)\n        _ , top_indices = torch.topk(expwts, k=topk, dim=-1, largest=True)\n        top_data = torch.ones_like(top_indices, dtype=previous_mask.dtype)\n\n        topk_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_indices,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Merge: previous  \u222a  top-k  \u222a  adaptive\n        # ------------------------------------------------------------------ #\n        merged = previous_mask.merge_mask(topk_mask, inplace=False)\n        merged = merged.merge_mask(adaptive_mask, inplace=False)\n        return merged\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace scale = 0.62 with 3 lines\nChange 2: Replace 13 lines with 32 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 2 (Score: 33.3333, Type: High-Performer)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"\n        Hybrid: top-k high-mass coverage plus aggressive adaptive budget for optimal sparsity and quality.\n\n        - First, select the minimum number of tokens per row (query) that account for at least 98% of exp(atten) mass.\n        - Then, for any long-tail, sample adaptively with an aggressive statistical error budget.\n        - This minimizes density while preserving near-full attention approximation.\n\n        The mask is the union of: (a) high-mass top-k mask, (b) adaptive random mask, (c) any previous mask.\n        \"\"\"\n\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        seq_len_keys = keys.shape[-2]\n        # More aggressive static for all seq lens, keeping parameterization stable\n        self.base_rate_sampling = 0.007\n        self.epsilon = 0.18\n        self.delta = 0.14\n        self.init_offset = 0.0\n        self.local_offset = 0.0\n\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Get tensor dimensions\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size, dims.num_heads, dims.seq_len_queries, dims.seq_len_keys\n        )\n\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # --------------- (1) Top-mass coverage ---------------\n        # For each (b, h, q), find minimum k s.t. cumsum(expwts) covers \u226598% of row mass.\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        mass_cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total_mass = mass_cumsum[..., -1:]\n        mass_frac = mass_cumsum / (total_mass + 1e-8)\n        k1 = (mass_frac < 0.98).sum(dim=-1, keepdim=True) + 1  # at least 1\n        # Cap k1 for extreme cases for sparsity\n        max_topk = min(16, seq_len_keys // 8)\n        k1 = torch.clamp(k1, min=2, max=max_topk)\n\n        max_k1 = int(k1.max())\n        row_indices = torch.arange(max_k1, device=expwts.device)[None, None, None, :]\n        k1_mask = (row_indices < k1)\n        expanded_sorted_idx = sorted_idx[..., :max_k1]\n        k1_selected_idx = torch.where(\n            k1_mask,\n            expanded_sorted_idx,\n            torch.zeros_like(expanded_sorted_idx),\n        )\n        k1_data = torch.where(\n            k1_mask,\n            torch.ones_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n            torch.zeros_like(expanded_sorted_idx, dtype=previous_mask.dtype),\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=k1_selected_idx,\n            data=k1_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # --------------- (2) Aggressive adaptive tail mask ---------------\n        # Statistical tail sampling as before, but with more sparsity\n        start_idx, end_idx, sampling_range = 0, seq_len_keys, seq_len_keys\n        num_base_samples = self._get_base_sample_count(sampling_range)\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        row_sampled_values = sampled_values.view(batch_size * num_heads * seq_len_queries, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        sampled_denominator = apply_inv_mask_sum(expwts, base_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Even more aggressively capped for long tails\n        min_budget = num_base_samples\n        max_budget = max(min_budget, int(0.05 * sampling_range))\n        rel_std = std_estimate / (estimated_denominator / sampling_range + 1e-8)\n        # Ultra sparse for low-variance rows\n        shrink = torch.where(rel_std < 0.13, 0.27, 0.53)\n        budget = torch.clamp(torch.ceil(budget_squared * shrink).long(), min=min_budget, max=max_budget)\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        # For rows with nearly flat dist, skip tail sampling (use only top-mass, keep at least min_budget)\n        flat_row = (rel_std < 0.05).squeeze(-1)\n        if torch.any(flat_row):\n            budget = torch.where(flat_row, torch.full_like(budget, min_budget), budget)\n            sampling_probabilities = torch.where(\n                flat_row, torch.full_like(sampling_probabilities, min_budget/sampling_range), sampling_probabilities\n            )\n\n        tail_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge everything: previous mask OR topmass_mask OR tail_mask\n        merged_mask = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(tail_mask, inplace=False)\n        return merged_mask\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 117 lines with 144 lines, Excellent density (100.000), Excellent error (100.000)\n\n\n### Inspiration 3 (Score: -0.0544, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        self.budget_scale = 0.75\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Increase minimum to 3 for better std stability, ceil for more robust estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(3, self.base_rate_sampling)\n        return max(3, int(torch.ceil(torch.tensor(self.base_rate_sampling * sampling_range)).item()))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        # Make sparsification more aggressive; lower scale, and cap budget per row\n        scale = 0.62\n        budget = torch.ceil(budget.float() * scale).long()\n\n        # Always ensure at least 2 per row (no degenerate rows)\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # Cap: at most 10% of available keys per query, but no less than min_base\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        budget = torch.clamp(budget, min=2)  # extra lower-bound\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge the newly created mask with the previous one\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 6 lines with 6 lines\nChange 2: Replace 20 lines with 28 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 4 (Score: -0.0552, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n        # (1) softly shrink the budget\n        budget = torch.ceil(budget.float() * 0.85).long()\n\n        # (2) respect lower-bound for numerical stability\n        budget = torch.clamp(budget, min=num_base_samples)\n\n        # (3) hard cap: at most 15 % of the available keys per row\n        max_budget = max(num_base_samples, int(0.15 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Re-compute sampling probabilities after final budget adjustment\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Create adaptive mask and merge with the previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 26 lines with 28 lines, Alternative density approach, Alternative error approach\n\n\n### Inspiration 5 (Score: -0.0543, Type: Exploratory)\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n        # ------------------------------------------------------------------ #\n        # NEW \u2013 extra sparsification while keeping statistical guarantees\n        # ------------------------------------------------------------------ #\n\n        # (1) Aggressively shrink the statistical budget\n        budget = torch.ceil(budget.float() * 0.62).long()\n\n        # (2) Increase base sample count for better std estimation at low density\n        min_base = max(num_base_samples, 3)\n        budget = torch.clamp(budget, min=min_base)\n\n        # (3) More aggressive cap: at most 10 % of the available keys per row\n        max_budget = max(min_base, int(0.10 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # (4) Set even lower bound for budget for short sequence regions\n        budget = torch.clamp(budget, min=2)\n\n        # Re-compute sampling probabilities after final budget adjustment\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n\n        # Create adaptive mask and merge with the previous one\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # EVOLVE-BLOCK-END\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\nUnique approach: Modification: Change 1: Replace 28 lines with 33 lines, Alternative density approach, Alternative error approach\n\n\n\n# Current Program\n```python\n\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        self.base_rate_sampling = 0.01\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 2 samples since it is used for std estimation\n        if isinstance(self.base_rate_sampling, int):\n            return max(2, self.base_rate_sampling)\n        return max(2, int(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # ------------------------------------------------------------------ #\n        # Extra sparsification while preserving quality\n        # ------------------------------------------------------------------ #\n        # 1) shrink theoretical budget\n        budget = torch.ceil(budget.float() * 0.70).long()\n\n        # 2) lower-bound for numerical stability\n        min_budget = max(num_base_samples, 2)\n        budget = torch.clamp(budget, min=min_budget)\n\n        # 3) hard cap \u2013 at most 12 % of the candidate keys\n        max_budget = max(min_budget, int(0.12 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Merge with previous mask and return\n        # ------------------------------------------------------------------ #\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["<<<<<<< SEARCH\n        # ------------------------------------------------------------------ #\n        # Extra sparsification while preserving quality\n        # ------------------------------------------------------------------ #\n        # 1) shrink theoretical budget\n        budget = torch.ceil(budget.float() * 0.70).long()\n\n        # 2) lower-bound for numerical stability\n        min_budget = max(num_base_samples, 2)\n        budget = torch.clamp(budget, min=min_budget)\n\n        # 3) hard cap \u2013 at most 12 % of the candidate keys\n        max_budget = max(min_budget, int(0.12 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # ------------------------------------------------------------------ #\n        # Merge with previous mask and return\n        # ------------------------------------------------------------------ #\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n=======\n        # ------------------------------------------------------------------ #\n        # Improved: Hybrid deterministic top-mass + aggressive adaptive tail\n        # ------------------------------------------------------------------ #\n\n        # (1) Deterministic selection: minimal top-k to cover 98% exp(attn) mass\n        sorted_expwts, sorted_idx = torch.sort(expwts, dim=-1, descending=True)\n        cumsum = torch.cumsum(sorted_expwts, dim=-1)\n        total = cumsum[..., -1:]\n        k_98 = (cumsum / (total + 1e-8) < 0.98).sum(dim=-1, keepdim=True) + 1\n        # Safety: at least 2, cap to 16 for memory efficiency\n        k_98 = torch.clamp(k_98, min=2, max=min(16, seq_len_keys // 8))\n        max_topk = int(k_98.max())\n        rows = torch.arange(max_topk, device=expwts.device)[None, None, None, :]\n        mask_top = rows < k_98\n        top_idx = sorted_idx[..., :max_topk]\n        top_data = torch.where(\n            mask_top, torch.ones_like(top_idx, dtype=previous_mask.dtype), torch.zeros_like(top_idx, dtype=previous_mask.dtype)\n        )\n        topmass_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=top_idx,\n            data=top_data,\n            type=\"index\",\n            dtype=previous_mask.dtype,\n        )\n\n        # (2) Adaptive statistical tail (aggressive)\n        # shrink theoretical budget further, but not lower than strict minimum for stability\n        min_base = max(num_base_samples, 3)\n        scale = torch.where((cumsum[..., -1:] / (static_denominator + 1e-8)) > 0.98, 0.40, 0.62)\n        # If most of the mass is already covered, shrink the tail aggressively\n\n        budget = torch.ceil(budget.float() * scale).long()\n        budget = torch.clamp(budget, min=min_base)\n        max_budget = max(min_base, int(0.08 * sampling_range))\n        budget = torch.clamp(budget, max=max_budget)\n        # Ignore tail for very-short rows (where 98% mass < 4 tokens)\n        budget = torch.where(k_98 >= seq_len_keys - 2, torch.full_like(budget, 0), budget)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Final: mask is (prev \u222a top-mass \u222a tail)\n        merged = previous_mask.merge_mask(topmass_mask, inplace=False).merge_mask(adaptive_mask, inplace=False)\n        return merged\n        # EVOLVE-BLOCK-END\n\n    @classmethod\n>>>>>>> REPLACE"]}}}