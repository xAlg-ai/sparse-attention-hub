{"id": "f3552db9-9ee3-4c3c-9036-7852d9e300fd", "code": "\"\"\"OpenEvolve masker implementation.\n\nThis module provides the OpenEvolve masker that implements evolutionary attention patterns.\nThe current implementation is a bare metal version that returns the previous mask.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict\n\nimport torch\nimport math\nfrom scipy.stats import norm\n\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers import (\n    ResearchMasker,\n)\nfrom sparse_attention_hub.sparse_attention.research_attention.maskers.base import (\n    MaskerConfig,\n    MaskerRegistry,\n)\nfrom sparse_attention_hub.sparse_attention.utils.mask import Mask\nfrom sparse_attention_hub.sparse_attention.utils.mask_attention_utils import (\n    _get_num_key_value_groups,\n    apply_inv_mask_sum,\n    create_sampling_mask_with_per_head_budget,\n    repeat_kv,\n)\n\n\n@dataclass\nclass OpenEvolveMaskerConfig(MaskerConfig):\n    \"\"\"Configuration for OpenEvolveMasker.\n\n    This configuration class inherits from MaskerConfig and provides\n    parameters for the attention mechanism evolved out of openevolve.\n    empty placeholder\n    \"\"\"\n\n    pass\n\n\n@MaskerRegistry.register(OpenEvolveMaskerConfig)\nclass OpenEvolveMasker(ResearchMasker):\n    \"\"\"OpenEvolve masker for evolutionary attention computation.\n\n    This masker implements evolutionary attention patterns that adapt over time.\n    The current implementation is a bare metal version that returns the previous mask.\n\n    Attributes:\n        evolution_rate: The rate of evolution for attention patterns.\n            This value is set from the configuration and controls how quickly\n            the attention patterns evolve.\n\n    Important Notes:\n        - This is a bare metal implementation that simply returns the previous mask.\n        - Future implementations will include evolutionary algorithms for attention pattern optimization.\n        - The evolution_rate parameter is currently unused but will be utilized in future versions.\n\n    Example:\n        >>> config = OpenEvolveMaskerConfig(evolution_rate=1.0)\n        >>> masker = OpenEvolveMasker(config)\n        >>> # Use masker.add_mask() to apply evolutionary attention patterns\n    \"\"\"\n\n    def __init__(self, config: OpenEvolveMaskerConfig) -> None:\n        \"\"\"Initialize OpenEvolve masker with configuration.\n\n        Args:\n            config: Configuration object containing the evolution rate and other\n                parameters for the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the evolution_rate in config is negative.\n                This validation is performed in the config's __post_init__ method.\n        \"\"\"\n        # Slightly larger systematic exploration\n        self.base_rate_sampling = 0.015\n        self.epsilon = 0.3\n        self.delta = 0.3\n        self.init_offset = 0.001\n        self.local_offset = 0.001\n        # New hyper-parameter: shrink the theoretical sampling\n        # budget by a constant factor to lower density while\n        # keeping the approximation quality virtually intact.\n        # Slightly relaxed to improve accuracy.\n        self.budget_scale = 0.80\n\n        super().__init__(config)\n\n    def _compute_exp_attention_scores(\n        self,\n        queries: torch.Tensor,\n        keys: torch.Tensor,\n        scaling: float,\n        attention_mask: torch.Tensor,\n    ) -> torch.Tensor:\n        \"\"\"Compute exponential attention scores with numerical stability.\"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n        raw_scores = torch.matmul(queries, keys.transpose(-2, -1)) * scaling\n        if attention_mask is not None:\n            raw_scores = raw_scores + attention_mask[:, :, :, : keys.shape[-2]]\n        max_scores = torch.max(raw_scores, dim=-1, keepdim=True)[0]\n        return torch.exp(raw_scores - max_scores)\n\n    def _get_sampling_range(self, seq_len_keys: int) -> tuple[int, int, int]:\n        \"\"\"Get sampling range and validate it.\n\n        Args:\n            seq_len_keys: Number of keys in the sequence.\n\n        Returns:\n            Tuple of (start_idx, end_idx, sampling_range).\n\n        Raises:\n            ValueError: If the computed sampling range is invalid.\n        \"\"\"\n        # Compute start index\n        if isinstance(self.init_offset, float):\n            start_idx: int = int(self.init_offset * seq_len_keys)\n        else:\n            start_idx = self.init_offset\n\n        # Compute end index\n        if isinstance(self.local_offset, float):\n            end_idx: int = seq_len_keys - int(self.local_offset * seq_len_keys)\n        else:\n            end_idx = seq_len_keys - self.local_offset\n\n        sampling_range = end_idx - start_idx\n\n        if sampling_range <= 0:\n            raise ValueError(f\"Invalid sampling range: {sampling_range}\")\n\n        return start_idx, end_idx, sampling_range\n\n    def _get_base_sample_count(self, sampling_range: int) -> int:\n        \"\"\"Get number of base samples based on configuration.\"\"\"\n        # Ensure at least 4 samples (better variance estimate for tiny budgets)\n        if isinstance(self.base_rate_sampling, int):\n            return max(4, self.base_rate_sampling)\n        # Use ceil so that very small ranges still receive at least one full sample per %\n        return max(4, math.ceil(self.base_rate_sampling * sampling_range))\n\n    def _get_std_estimate_using_base_sample(\n        self,\n        expwts: torch.Tensor,\n        batch_size: int,\n        num_heads: int,\n        seq_len_queries: int,\n        seq_len_keys: int,\n        start_idx: int,\n        end_idx: int,\n        num_base_samples: int,\n        dtype: torch.dtype,\n    ) -> tuple[Mask, torch.Tensor]:\n        \"\"\"Get standard deviation estimate using base sampling and create base mask.\"\"\"\n        # Create base sampling indices\n        base_row_wise_idx = torch.randint(\n            low=start_idx,\n            high=end_idx,\n            size=(batch_size, num_heads, seq_len_queries, num_base_samples),\n            device=expwts.device,\n        )\n\n        # Extract values and compute std\n        sampled_values = torch.gather(expwts, dim=-1, index=base_row_wise_idx)\n        total_rows = batch_size * num_heads * seq_len_queries\n        row_sampled_values = sampled_values.view(total_rows, num_base_samples)\n        std_estimate = torch.std(row_sampled_values, dim=-1, keepdim=True)\n        std_estimate = torch.clamp(std_estimate, min=1e-8)\n        std_estimate = std_estimate.view(batch_size, num_heads, seq_len_queries, 1)\n\n        # Create base sampling mask\n        sampling_range = end_idx - start_idx\n        base_data = torch.full_like(\n            base_row_wise_idx, num_base_samples / sampling_range, dtype=expwts.dtype\n        )\n\n        base_mask = Mask.create_from_row_wise_idx(\n            shape=(batch_size, num_heads, seq_len_queries, seq_len_keys),\n            row_wise_idx=base_row_wise_idx,\n            data=base_data,\n            type=\"index\",\n            dtype=dtype,\n        )\n\n        return base_mask, std_estimate\n\n    def _compute_adaptive_budget(\n        self,\n        std_estimate: torch.Tensor,\n        estimated_denominator: torch.Tensor,\n        sampling_range: int,\n    ) -> torch.Tensor:\n        \"\"\"Compute adaptive budget based on statistical bounds.\"\"\"\n        epsilon_allowable_error = self.epsilon * estimated_denominator\n        epsilon_allowable_error = torch.clamp(epsilon_allowable_error, min=1e-8)\n\n        budget_numerator = self.delta_ppf * std_estimate * sampling_range\n        budget_squared = (budget_numerator / epsilon_allowable_error) ** 2\n\n        # Ensure budget is positive and within bounds\n        budget = torch.clamp(\n            budget_squared,\n            min=1.0,  # Minimum 1 sample\n            max=float(sampling_range),  # Maximum sampling_range samples\n        ).long()\n\n        return budget\n\n    def add_mask(\n        self,\n        keys: torch.Tensor,\n        queries: torch.Tensor,\n        values: torch.Tensor,\n        attention_mask: torch.Tensor,\n        scaling: float,\n        dropout: float,\n        sparse_meta_data: Dict[Any, Any],\n        previous_mask: Mask,\n        **kwargs: Dict[str, Any],\n    ) -> Mask:\n        \"\"\"Add adaptive sampling mask to attention computation.\n\n        This method implements the core adaptive sampling logic. It combines base\n        sampling with adaptive budget allocation based on statistical error bounds.\n\n        Args:\n            keys: Key tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            queries: Query tensor with shape (batch_size, num_heads, seq_len_queries, head_dim).\n            values: Value tensor with shape (batch_size, num_heads, seq_len_keys, head_dim).\n            attention_mask: Attention mask tensor indicating which positions are valid.\n            sparse_meta_data: Dictionary containing sparse attention metadata.\n            previous_mask: Previous attention mask to merge with the new adaptive sampling mask.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A new Mask object representing the attention pattern after applying\n            adaptive sampling.\n\n        Raises:\n            ValueError: If the sampling range is invalid.\n        \"\"\"\n        ngroups = _get_num_key_value_groups(queries, keys)\n        keys = repeat_kv(keys, ngroups)\n\n        # EVOLVE-BLOCK-START\n\n        # PARAMETERS to be set - ITERATION 3: Dynamic parameter adaptation (BEST PERFORMANCE)\n        # Adaptive parameters based on sequence length\n        seq_len_keys = keys.shape[-2]\n        if seq_len_keys > 10000:\n            self.base_rate_sampling = 0.02  # Higher sampling for very long sequences\n            self.epsilon = 0.2  # Tighter bounds for long sequences\n            self.delta = 0.2\n        elif seq_len_keys > 5000:\n            self.base_rate_sampling = 0.018  # Medium sampling for long sequences\n            self.epsilon = 0.22  # Medium bounds\n            self.delta = 0.22\n        else:\n            self.base_rate_sampling = 0.015  # Default for shorter sequences\n            self.epsilon = 0.25\n            self.delta = 0.25\n\n        self.init_offset = 0.002\n        self.local_offset = 0.002\n\n        # Pre-compute delta_ppf for efficiency\n        self.delta_ppf = float(norm.ppf(1 - self.delta))\n\n        if previous_mask.is_full_mask():\n            return previous_mask\n\n        # Extract dimensions and compute attention scores\n        dims = self._extract_tensor_dimensions(keys, queries)\n        batch_size, num_heads, seq_len_queries, seq_len_keys = (\n            dims.batch_size,\n            dims.num_heads,\n            dims.seq_len_queries,\n            dims.seq_len_keys,\n        )\n        # Compute attention scores after removing attention_mask\n        expwts = self._compute_exp_attention_scores(\n            queries, keys, scaling, attention_mask\n        )\n        static_denominator = apply_inv_mask_sum(expwts, previous_mask)\n\n        # Get sampling parameters\n        start_idx, end_idx, sampling_range = self._get_sampling_range(seq_len_keys)\n        num_base_samples = self._get_base_sample_count(sampling_range)\n\n        # Create base sampling mask and estimate std\n        base_sampling_mask, std_estimate = self._get_std_estimate_using_base_sample(\n            expwts,\n            batch_size,\n            num_heads,\n            seq_len_queries,\n            seq_len_keys,\n            start_idx,\n            end_idx,\n            num_base_samples,\n            previous_mask.dtype,\n        )\n        # Compute denominators and budget\n        sampled_denominator = apply_inv_mask_sum(expwts, base_sampling_mask)\n        estimated_denominator = static_denominator + sampled_denominator\n        budget = self._compute_adaptive_budget(\n            std_estimate, estimated_denominator, sampling_range\n        )\n\n        # Shrink the statistical budget \u2013 empirically gives the\n        # same error with considerably fewer active tokens.\n        budget = (budget.float() * self.budget_scale).ceil().long()\n\n        # Keep the budget in valid bounds\n        budget = torch.clamp(budget, min=num_base_samples, max=sampling_range)\n\n        # Create adaptive sampling mask\n        sampling_probabilities = (budget / sampling_range).to(previous_mask.dtype)\n        adaptive_mask = create_sampling_mask_with_per_head_budget(\n            budgets=budget,\n            sampling_probability=sampling_probabilities,\n            seq_len_keys=seq_len_keys,\n            start_idx=start_idx,\n            end_idx=end_idx,\n            dtype=previous_mask.dtype,\n        )\n\n        # Merge the newly created mask with the previous one\n        return previous_mask.merge_mask(adaptive_mask, inplace=False)\n\n        # EVOLVE-BLOCK-END\n        # (unreachable duplicate code removed)\n        pass\n\n    @classmethod\n    def create_from_config(cls, config: MaskerConfig) -> \"OpenEvolveMasker\":\n        \"\"\"Create OpenEvolve masker instance from configuration.\n\n        Args:\n            config: Configuration for the OpenEvolve masker.\n\n        Returns:\n            Instance of the OpenEvolve masker.\n\n        Raises:\n            ValueError: If the config type is invalid.\n        \"\"\"\n        # not checking for config type here since we will be replacing this masker class\n        # with the new masker class in the evaluator.py file\n        return cls(config)\n", "language": "python", "parent_id": "dcdecb26-de4d-4014-b278-8a7ae192d49e", "generation": 2, "timestamp": 1757484470.2553663, "iteration_found": 8, "metrics": {"density": -0.07693281897620162, "error": -0.03494000434875488, "combined_score": -0.05593641166247825}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 3 lines\nChange 2: Replace self.base_rate_sampling = 0.01 with 2 lines\nChange 3: Replace 4 lines with 5 lines\nChange 4: Replace 6 lines with 7 lines", "parent_metrics": {"density": -0.07603889663987966, "error": -0.03496372699737549, "combined_score": -0.05550131181862757}, "island": 0}, "artifacts_json": null, "artifact_dir": null}